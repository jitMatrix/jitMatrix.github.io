<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>R and OpenMP:  CRAN Package Modernization | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Indeed, a major current trend in R is what might be called “R+X”, where X is some other language or library. –Norman Matloff, Parallel Computing for Data Science  IntroductionNowadays, there are more">
<meta property="og:type" content="article">
<meta property="og:title" content="R and OpenMP:  CRAN Package Modernization">
<meta property="og:url" content="https://jitmatrix.github.io/oneXPU/2016/08/15/r-cran-package-modernization-openmp/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Indeed, a major current trend in R is what might be called “R+X”, where X is some other language or library. –Norman Matloff, Parallel Computing for Data Science  IntroductionNowadays, there are more">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://www.parallelr.com/wp-content/uploads/2016/05/cycle-2.png">
<meta property="og:image" content="http://www.parallelr.com/wp-content/uploads/2016/05/KNN-3.png">
<meta property="article:published_time" content="2016-08-15T02:55:52.000Z">
<meta property="article:modified_time" content="2020-12-19T06:26:33.163Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="rstats">
<meta property="article:tag" content="openMP">
<meta property="article:tag" content="R">
<meta property="article:tag" content="CRAN">
<meta property="article:tag" content="knn">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://www.parallelr.com/wp-content/uploads/2016/05/cycle-2.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://jitmatrix.github.io/oneXPU"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-r-cran-package-modernization-openmp" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2016/08/15/r-cran-package-modernization-openmp/" class="article-date">
  <time class="dt-published" datetime="2016-08-15T02:55:52.000Z" itemprop="datePublished">2016-08-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Accelerators/">Accelerators</a>►<a class="article-category-link" href="/categories/Accelerators/MultiCores/">MultiCores</a>►<a class="article-category-link" href="/categories/Accelerators/MultiCores/Performance-Optimizaiton/">Performance Optimizaiton</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      R and OpenMP:  CRAN Package Modernization
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <hr>
<p><em>Indeed, a major current trend in R is what might be called “R+X”, where X is some other language or library.</em> <em>–Norman Matloff, Parallel Computing for Data Science</em></p>
<hr>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><strong>Nowadays,</strong> there are more than 8000 packages in CRAN (till April 2016 from Revolution Analytics  <a target="_blank" rel="noopener" href="http://blog.revolutionanalytics.com/2016/04/a-segmented-model-of-cran-package-growth.html">Blog</a>) and even more, packages locate in GitHub and R-forge. Meanwhile, most of us heavily rely on these packages for our daily analytical work. With the increasing amount of data as well as the diversification of data sources (such as image, speech, and video), data scientists will be experience performance issues.  Though there already have parallel solutions for us (check out <a target="_blank" rel="noopener" href="https://cran.r-project.org/web/views/HighPerformanceComputing.html">HPCR list</a>), we will fall into the case soon or later that no parallelized package is available in CRAN or GitHub. Therefore, we have to consider to implement specified parallel algorithm by ourselves. In general, you can design and implement the parallel algorithm from scratch or parallelize the existing packages.  If you are working on writing the parallel code from scratch, I recommend Prof. Matloff’s new book_, <a target="_blank" rel="noopener" href="https://www.amazon.com/Parallel-Computing-Data-Science-Examples/dp/1466587016">Parallel Computing for Data Science</a>_, and Dr. OTT’s blog <em><a target="_blank" rel="noopener" href="http://www.parallelr.com/r-and-openmp-boosting-compiled-code-on-multi-core-cpu-s/">R and openMP: boosting compiled code on multi-core cpu-s</a>.</em> In this post, I will introduce the basic workflow and skills for accelerating legacy R package by OpenMP, and this produce is called <a target="_blank" rel="noopener" href="https://software.intel.com/en-us/articles/what-is-code-modernization">code modernization</a>. Sometimes, acceleration legacy code is more challenge than writing parallel algorithm by yourself because we have to work on original software architecture and implementation, and try to minimal changes as much as possible. In below cycle chart, I illustrate several basic steps of code modernization and I am going to introduce each of steps in the below chapters with <a target="_blank" rel="noopener" href="https://cran.r-project.org/web/packages/class/class.pdf">KNN {class}</a> function, written by Prof. Brian Ripley, for example.   <a target="_blank" rel="noopener" href="http://www.parallelr.com/wp-content/uploads/2016/05/cycle-2.png"><img src="http://www.parallelr.com/wp-content/uploads/2016/05/cycle-2.png"></a>  </p>
<h1 id="Understand-Algorithm-and-Code"><a href="#Understand-Algorithm-and-Code" class="headerlink" title="Understand Algorithm and Code"></a>Understand Algorithm and Code</h1><p>First and most important step before speedup code is to understand the original algorithm and implementation as much as possible ranging from data structure, functionality to coding. Now, let us start with our example of <em>class</em> package and the major function of K nearest neighbors algorithm (<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">KNN</a>). The algorithm of KNN can be shown as below chart. There are three steps. First, compute the distance from each observation of train dataset to each of test dataset, and then select K nearest from distance results (the direct approach is to sort the results and select first K elements). Finally, most voted group will win, or if several groups have the same accounts, just <strong>RANDOM</strong> breaking (Notes: this random breaking will cause little trouble in parallel version, consider why, and I will give more details later). <a target="_blank" rel="noopener" href="http://www.parallelr.com/wp-content/uploads/2016/05/KNN-3.png"><img src="http://www.parallelr.com/wp-content/uploads/2016/05/KNN-3.png"></a>   Next, we’re going through the source code and match each step of KNN with their implementations. Checking the body of R Knn, you can see the real algorithm is locate in C level and R function is only a wrapper. [code language=”r”] &gt;library(class) &gt;knn function (train, test, cl, k = 1, l = 0, prob = FALSE, use.all = TRUE) { # skip Z &lt;- .C(VR_knn, as.integer(k), as.integer(l), as.integer(ntr),….)) # skip } [/code] So, switching to VR_knn function in your local repository (class.c) or from GitHub (<a target="_blank" rel="noopener" href="https://github.com/cran/class/blob/master/src/class.c">here</a>), totally there are about 100 lines. And the code is organized very clearly and we can quickly identify the 3 steps with my highlight comments. [code language=”C”] VR_knn(Sint *kin, Sint *lin, Sint *pntr, Sint *pnte, Sint *p, double *train, Sint *class, double *test, Sint *res, double *pr, Sint *votes, Sint *nc, Sint *cv, Sint *use_all) { // skip … // Peng: main loop for (npat = 0; npat &lt; nte; npat++) { // Peng: Step.1 – compute distance for (k = 0; k &lt; *p; k++) { tmp = test[npat + k * nte] - train[j + k * ntr]; dist += tmp * tmp; } // skip … // Peng: Step.2 – select K nearest /* Use ‘fuzz’ since distance computed could depend on order of coordinates */ if (dist &lt;= nndist[kinit - 1] * (1 + EPS)) for (k = 0; k &lt;= kn; k++) if (dist &lt; nndist[k]) { for (k1 = kn; k1 &gt; k; k1–) { nndist[k1] = nndist[k1 - 1]; pos[k1] = pos[k1 - 1]; } // Peng: Step.3 – voting and breaking for (j = 0; j &lt;= *nc; j++) votes[j] = 0; if (*use_all) { for (j = 0; j &lt;; kinit; j++) // skip … } &lt;span class=”pl-k”&gt;else&lt;/span&gt; { &lt;span class=”pl-c”&gt;/* break ties at random */ &lt;/span&gt; // skip … } // Peng: Final results res[npat] = index; pr[npat] = (double) mm / (kinit + extras); } // Peng: end of main loop RANDOUT; } [/code]</p>
<h1 id="Identify-Bottleneck"><a href="#Identify-Bottleneck" class="headerlink" title="Identify Bottleneck"></a>Identify Bottleneck</h1><p>Two kinds of applications for parallelization can be divided into computer and memory intensive. OpenMP is used to resolve compute-intensive applications with multiple threads while message passing interface (<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Message_Passing_Interface">MPI</a>) can be applied reduce local memory requirements by distributing the application in different machines. Therefore, we need to determine whether the package we are dealing with is compute-intensive and where the most time-consuming parts are. To do this, we can do a simple complexity analysis from algorithm view. Still using KNN for example as our description, we see the computational complexity in Step 1 is O(M*N*Q) since we iterate through train (M lines) and test (N lines) dataset and compute the distance with K features. Step 2 is sorting and the worst computational complexity is O(M*K) and Step 3 is only the linear complexity of O(K). Regarding with memory requirements, the most size is the two input dataset with O(M*Q) and O(N*Q) in Step 1. Totally, the computational complexity of KNN is <strong>THREE</strong> power while the memory usage is only <strong>TWO</strong> power. So, the OpenMP is appropriate.</p>
<h1 id="Specify-Parallel-Region"><a href="#Specify-Parallel-Region" class="headerlink" title="Specify Parallel Region"></a>Specify Parallel Region</h1>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://jitmatrix.github.io/oneXPU/2016/08/15/r-cran-package-modernization-openmp/" data-id="ckivbjgo9000g6lolb1js0zc4" data-title="R and OpenMP:  CRAN Package Modernization" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CRAN/" rel="tag">CRAN</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/R/" rel="tag">R</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/knn/" rel="tag">knn</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/openMP/" rel="tag">openMP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/rstats/" rel="tag">rstats</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/09/10/r-with-parallel-computing/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          R with Parallel Computing from User Perspectives
        
      </div>
    </a>
  
  
    <a href="/2016/07/26/r-and-openmp-boosting-compiled-code-on-multi-core-cpu-s/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">R and openMP: boosting compiled code on multi-core cpu-s</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/">Accelerators</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/GPGPU/">GPGPU</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/GPGPU/MultiCores/">MultiCores</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/GPGPU/Performance-Optimizaiton/">Performance Optimizaiton</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/General/">General</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/General/GPGPU/">GPGPU</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/General/GPGPU/MultiCores/">MultiCores</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/General/GPGPU/MultiCores/Performance-Optimizaiton/">Performance Optimizaiton</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/General/MPI/">MPI</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/General/MPI/MultiCores/">MultiCores</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/General/MPI/MultiCores/Performance-Optimizaiton/">Performance Optimizaiton</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/General/MPI/MultiCores/Performance-Optimizaiton/Vectorization/">Vectorization</a></li></ul></li></ul></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/MultiCores/">MultiCores</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/MultiCores/Performance-Optimizaiton/">Performance Optimizaiton</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/MultiCores/Vectorization/">Vectorization</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/GPGPU/">GPGPU</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/GPGPU/Intel-Xeon-Phi/">Intel Xeon Phi</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GPGPU/MultiCores/">MultiCores</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/GPGPU/MultiCores/Performance-Optimizaiton/">Performance Optimizaiton</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/General/">General</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/General/MultiCores/">MultiCores</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Uncategorized/">Uncategorized</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/BLAS/" rel="tag">BLAS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CRAN/" rel="tag">CRAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GEMM/" rel="tag">GEMM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GPU/" rel="tag">GPU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/H2O/" rel="tag">H2O</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HPAC/" rel="tag">HPAC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HPC/" rel="tag">HPC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MIC/" rel="tag">MIC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MKL/" rel="tag">MKL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MNIST/" rel="tag">MNIST</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Maximum-Likelihood/" rel="tag">Maximum Likelihood</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/R/" rel="tag">R</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Rcpp/" rel="tag">Rcpp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SSE/" rel="tag">SSE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Xeon/" rel="tag">Xeon</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Xeon-Phi/" rel="tag">Xeon Phi</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/benchmark/" rel="tag">benchmark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/big-data/" rel="tag">big data</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/boost/" rel="tag">boost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/classification/" rel="tag">classification</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cuBLAS/" rel="tag">cuBLAS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/data-analytics/" rel="tag">data analytics</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/deep-learning/" rel="tag">deep learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dnn/" rel="tag">dnn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/doMC/" rel="tag">doMC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/doParallel/" rel="tag">doParallel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/foreach/" rel="tag">foreach</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gmatrix/" rel="tag">gmatrix</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gpuR/" rel="tag">gpuR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gputools/" rel="tag">gputools</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/high-performance/" rel="tag">high performance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/iris/" rel="tag">iris</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/knn/" rel="tag">knn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lightboost/" rel="tag">lightboost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learing/" rel="tag">machine learing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mcapply/" rel="tag">mcapply</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/memory-usage/" rel="tag">memory usage</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/multicores/" rel="tag">multicores</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/multit/" rel="tag">multit</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/multithreads/" rel="tag">multithreads</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mutlithreading/" rel="tag">mutlithreading</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mutltiGPU/" rel="tag">mutltiGPU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/neural-network/" rel="tag">neural network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nvblas/" rel="tag">nvblas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/openMP/" rel="tag">openMP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/openblas/" rel="tag">openblas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/parallel/" rel="tag">parallel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/parallel-computing/" rel="tag">parallel computing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/parlapply/" rel="tag">parlapply</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/performance-optimization/" rel="tag">performance optimization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/profiling/" rel="tag">profiling</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rstats/" rel="tag">rstats</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sklearn/" rel="tag">sklearn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/snow/" rel="tag">snow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/xgboost/" rel="tag">xgboost</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/BLAS/" style="font-size: 10px;">BLAS</a> <a href="/tags/CRAN/" style="font-size: 10px;">CRAN</a> <a href="/tags/CUDA/" style="font-size: 12px;">CUDA</a> <a href="/tags/GEMM/" style="font-size: 12px;">GEMM</a> <a href="/tags/GPU/" style="font-size: 14px;">GPU</a> <a href="/tags/H2O/" style="font-size: 12px;">H2O</a> <a href="/tags/HPAC/" style="font-size: 10px;">HPAC</a> <a href="/tags/HPC/" style="font-size: 12px;">HPC</a> <a href="/tags/MIC/" style="font-size: 10px;">MIC</a> <a href="/tags/MKL/" style="font-size: 14px;">MKL</a> <a href="/tags/MNIST/" style="font-size: 10px;">MNIST</a> <a href="/tags/Maximum-Likelihood/" style="font-size: 10px;">Maximum Likelihood</a> <a href="/tags/R/" style="font-size: 20px;">R</a> <a href="/tags/Rcpp/" style="font-size: 10px;">Rcpp</a> <a href="/tags/SSE/" style="font-size: 10px;">SSE</a> <a href="/tags/Xeon/" style="font-size: 10px;">Xeon</a> <a href="/tags/Xeon-Phi/" style="font-size: 10px;">Xeon Phi</a> <a href="/tags/benchmark/" style="font-size: 10px;">benchmark</a> <a href="/tags/big-data/" style="font-size: 10px;">big data</a> <a href="/tags/boost/" style="font-size: 10px;">boost</a> <a href="/tags/classification/" style="font-size: 10px;">classification</a> <a href="/tags/cuBLAS/" style="font-size: 16px;">cuBLAS</a> <a href="/tags/data-analytics/" style="font-size: 12px;">data analytics</a> <a href="/tags/deep-learning/" style="font-size: 14px;">deep learning</a> <a href="/tags/dnn/" style="font-size: 12px;">dnn</a> <a href="/tags/doMC/" style="font-size: 10px;">doMC</a> <a href="/tags/doParallel/" style="font-size: 10px;">doParallel</a> <a href="/tags/foreach/" style="font-size: 10px;">foreach</a> <a href="/tags/gmatrix/" style="font-size: 10px;">gmatrix</a> <a href="/tags/gpuR/" style="font-size: 10px;">gpuR</a> <a href="/tags/gputools/" style="font-size: 10px;">gputools</a> <a href="/tags/high-performance/" style="font-size: 10px;">high performance</a> <a href="/tags/iris/" style="font-size: 10px;">iris</a> <a href="/tags/knn/" style="font-size: 10px;">knn</a> <a href="/tags/lightboost/" style="font-size: 10px;">lightboost</a> <a href="/tags/machine-learing/" style="font-size: 10px;">machine learing</a> <a href="/tags/machine-learning/" style="font-size: 12px;">machine learning</a> <a href="/tags/mcapply/" style="font-size: 10px;">mcapply</a> <a href="/tags/memory-usage/" style="font-size: 10px;">memory usage</a> <a href="/tags/multicores/" style="font-size: 18px;">multicores</a> <a href="/tags/multit/" style="font-size: 10px;">multit</a> <a href="/tags/multithreads/" style="font-size: 10px;">multithreads</a> <a href="/tags/mutlithreading/" style="font-size: 10px;">mutlithreading</a> <a href="/tags/mutltiGPU/" style="font-size: 10px;">mutltiGPU</a> <a href="/tags/neural-network/" style="font-size: 10px;">neural network</a> <a href="/tags/nvblas/" style="font-size: 10px;">nvblas</a> <a href="/tags/openMP/" style="font-size: 12px;">openMP</a> <a href="/tags/openblas/" style="font-size: 12px;">openblas</a> <a href="/tags/parallel/" style="font-size: 10px;">parallel</a> <a href="/tags/parallel-computing/" style="font-size: 18px;">parallel computing</a> <a href="/tags/parlapply/" style="font-size: 10px;">parlapply</a> <a href="/tags/performance-optimization/" style="font-size: 16px;">performance optimization</a> <a href="/tags/profiling/" style="font-size: 12px;">profiling</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/rstats/" style="font-size: 20px;">rstats</a> <a href="/tags/sklearn/" style="font-size: 10px;">sklearn</a> <a href="/tags/snow/" style="font-size: 10px;">snow</a> <a href="/tags/xgboost/" style="font-size: 10px;">xgboost</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/04/07/r-hpac-benchmark-analysis-gpu/">R benchmark for High-Performance Analytics and Computing (II): GPU Packages</a>
          </li>
        
          <li>
            <a href="/2017/01/24/parallel-computation-with-r-and-xgboost/">Parallel Computation with R and XGBoost</a>
          </li>
        
          <li>
            <a href="/2016/09/10/r-with-parallel-computing/">R with Parallel Computing from User Perspectives</a>
          </li>
        
          <li>
            <a href="/2016/08/15/r-cran-package-modernization-openmp/">R and OpenMP:  CRAN Package Modernization</a>
          </li>
        
          <li>
            <a href="/2016/07/26/r-and-openmp-boosting-compiled-code-on-multi-core-cpu-s/">R and openMP: boosting compiled code on multi-core cpu-s</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2020 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>