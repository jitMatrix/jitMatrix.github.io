<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/oneXPU/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/oneXPU/oneXPU/uploads/favicon/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/oneXPU/oneXPU/uploads/favicon/favicon.ico">
  <link rel="mask-icon" href="/oneXPU/images/logo.svg" color="#222">

<link rel="stylesheet" href="/oneXPU/css/main.css">


<link rel="stylesheet" href="/oneXPU/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jitmatrix.github.io","root":"/oneXPU/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="This article is originally published in Capital of Statistic by Chinese [link] and I would like to thank He Tong for lots of great suggestions. All code in this post can be found on GitHub [link].  D">
<meta property="og:type" content="article">
<meta property="og:title" content="R with Parallel Computing from User Perspectives">
<meta property="og:url" content="https://jitmatrix.github.io/oneXPU/2016/09/10/r-with-parallel-computing/index.html">
<meta property="og:site_name" content="ParallelR">
<meta property="og:description" content="This article is originally published in Capital of Statistic by Chinese [link] and I would like to thank He Tong for lots of great suggestions. All code in this post can be found on GitHub [link].  D">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jitmatrix.github.io/oneXPU/uploads/2016/09/sunway-taihulight.jpg">
<meta property="og:image" content="https://jitmatrix.github.io/oneXPU/uploads/2016/09/cs.png">
<meta property="og:image" content="https://jitmatrix.github.io/oneXPU/uploads/2016/09/RPP.png">
<meta property="og:image" content="https://jitmatrix.github.io/oneXPU/uploads/2016/09/mm.png">
<meta property="og:image" content="https://jitmatrix.github.io/oneXPU/uploads/2016/09/ca.png">
<meta property="og:image" content="https://jitmatrix.github.io/oneXPU/uploads/2016/09/dist.png">
<meta property="og:image" content="https://jitmatrix.github.io/oneXPU/uploads/2016/09/mapping-1.png">
<meta property="og:image" content="https://jitmatrix.github.io/oneXPU/uploads/2016/09/EP.png">
<meta property="article:published_time" content="2016-09-10T09:10:31.000Z">
<meta property="article:modified_time" content="2020-12-19T10:54:08.385Z">
<meta property="article:author" content="Patric Zhao">
<meta property="article:tag" content="multicores">
<meta property="article:tag" content="rstats">
<meta property="article:tag" content="parallel computing">
<meta property="article:tag" content="R">
<meta property="article:tag" content="cuBLAS">
<meta property="article:tag" content="MKL">
<meta property="article:tag" content="BLAS">
<meta property="article:tag" content="doMC">
<meta property="article:tag" content="doParallel">
<meta property="article:tag" content="foreach">
<meta property="article:tag" content="mcapply">
<meta property="article:tag" content="parallel">
<meta property="article:tag" content="parlapply">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jitmatrix.github.io/oneXPU/uploads/2016/09/sunway-taihulight.jpg">

<link rel="canonical" href="https://jitmatrix.github.io/oneXPU/2016/09/10/r-with-parallel-computing/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>R with Parallel Computing from User Perspectives | ParallelR</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/oneXPU/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">ParallelR</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Diving into Parallel Technology</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/oneXPU/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/oneXPU/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-opensource">

    <a href="/oneXPU/opensource/" rel="section"><i class="fa fa-code fa-fw"></i>Opensource</a>

  </li>
        <li class="menu-item menu-item-presentation">

    <a href="/oneXPU/presentation/" rel="section"><i class="fa fa-file-powerpoint fa-fw"></i>Presentation</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/oneXPU/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/oneXPU/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/oneXPU/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jitmatrix.github.io/oneXPU/2016/09/10/r-with-parallel-computing/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/oneXPU/images/avatar.gif">
      <meta itemprop="name" content="Patric Zhao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ParallelR">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          R with Parallel Computing from User Perspectives
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2016-09-10 09:10:31" itemprop="dateCreated datePublished" datetime="2016-09-10T09:10:31+00:00">2016-09-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-12-19 10:54:08" itemprop="dateModified" datetime="2020-12-19T10:54:08+00:00">2020-12-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/oneXPU/categories/Accelerators/" itemprop="url" rel="index"><span itemprop="name">Accelerators</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/oneXPU/categories/Accelerators/General/" itemprop="url" rel="index"><span itemprop="name">General</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/oneXPU/categories/Accelerators/General/GPGPU/" itemprop="url" rel="index"><span itemprop="name">GPGPU</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/oneXPU/categories/Accelerators/General/GPGPU/MultiCores/" itemprop="url" rel="index"><span itemprop="name">MultiCores</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/oneXPU/categories/Accelerators/General/GPGPU/MultiCores/Performance-Optimizaiton/" itemprop="url" rel="index"><span itemprop="name">Performance Optimizaiton</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <hr>
<p><em>This article is originally published in <a target="_blank" rel="noopener" href="http://cos.name/">Capital of Statistic</a> by Chinese [<a target="_blank" rel="noopener" href="http://cos.name/2016/09/r-and-parallel-computing/">link</a>] and I would like to thank <a target="_blank" rel="noopener" href="http://www.sfu.ca/~hetongh/">He Tong</a> for lots of great suggestions.</em> <em>All code in this post can be found on GitHub [<a target="_blank" rel="noopener" href="https://github.com/PatricZhao/ParallelR/tree/master/PP_for_COS">link</a>].</em></p>
<hr>
<p>Data scientists are already very familiar with statistical software like <a target="_blank" rel="noopener" href="https://www.r-project.org/">R</a>, <a target="_blank" rel="noopener" href="http://www.sas.com/en_hk/home.html">SAS</a>, <a target="_blank" rel="noopener" href="http://www.ibm.com/analytics/us/en/technology/spss/">SPSS</a>, <a target="_blank" rel="noopener" href="http://www.mathworks.com/products/matlab">MATLAB</a>; however, some of them are relatively inexperienced in parallel computing. So, in this post, I will introduce you some basic concepts on the use of parallel computing in R.</p>
<h1 id="What-is-Parallel-Computing？"><a href="#What-is-Parallel-Computing？" class="headerlink" title="What is Parallel Computing？"></a>What is Parallel Computing？</h1><p><a target="_blank" rel="noopener" href="https://computing.llnl.gov/tutorials/parallel_comp/">Parallel computing</a>, specifically, should include <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Supercomputer">high-performance computers</a> and <a target="_blank" rel="noopener" href="http://whatis.techtarget.com/definition/parallel-processing-software">parallel software</a>. The peak performance of high-performance computers increases quickly. In the most recent ranking of the world’s TOP500 supercomputers, Chinese Sunway Taihu Light topped the list with 93 PFLOPS (<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Supercomputer">here</a>). For most individuals, small and medium enterprises, high-performance computers are too expensive. So, the application of high-performance computers is indeed limited, mainly in the field of national defense, military, aerospace and research areas. In recent years, with the rapid developments of multicore CPU, cheap cluster, and various accelerators (<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Nvidia_Tesla">NVIDIA GPU</a>, <a target="_blank" rel="noopener" href="http://www.intel.com/content/www/us/en/processors/xeon/xeon-phi-detail.html">Intel Xeon Phi</a>, <a target="_blank" rel="noopener" href="http://www.xilinx.com/training/fpga/fpga-field-programmable-gate-array.htm">FPGA</a>), personal computers has been comparable to high-performance computers. <a href="/oneXPU/uploads/2016/09/sunway-taihulight.jpg"><img src="/oneXPU/uploads/2016/09/sunway-taihulight.jpg" alt="sunway-taihulight"></a> On the other hand, the software changes lag a lot. Imagine what software you’re using  supported parallel operations, Chrome, Visual Studio or R? <a href="/oneXPU/uploads/2016/09/cs.png"><img src="/oneXPU/uploads/2016/09/cs.png" alt="common software"></a> Software parallelization requires more research and development supports. It is called <a target="_blank" rel="noopener" href="https://software.intel.com/en-us/articles/what-is-code-modernization">code modernization</a> for the procedure of changing the serial code to parallel, which sounds a very interesting work. But, in practice, a large number of bug fixes, data structure rewrite, uncertain software behaviors and cross-platform issues greatly increase the software development and maintenance costs.</p>
<h1 id="Why-R-Needs-Parallel-Computing"><a href="#Why-R-Needs-Parallel-Computing" class="headerlink" title="Why R Needs Parallel Computing?"></a>Why R Needs Parallel Computing?</h1><p>Let’s come back to R. As one of the most popular statistical software, R has a lot of advantages, such as a wealth of statistical models, data processing tools, and powerful visualization capabilities. However, with an increasing amount of data, R’s memory usage and computation mode limit R to scale. From the memory perspective, R uses in-memory calculation mode. All data need to be processed in the main memory (RAM). Obviously, its advantages are high computational efficiency and speed, but the drawback is that the size of the problem can be handled by R is very limited (&lt;RAM ). Secondly, R core is a single-threaded program. Thus, in the modern multi-core processors,  R can not effectively use all the computing cores. If the R went to the Sunway CPU of 260 computing cores, single-threaded R only take 1/260 computing power and waste other computing cores of 259/260.</p>
<h2 id="Solution？Parallel-Computing"><a href="#Solution？Parallel-Computing" class="headerlink" title="Solution？Parallel Computing!"></a><strong>Solution？Parallel Computing!</strong></h2><p>Parallel computing technology can solve the problem that single-core and memory capacity can not meet the application needs. Thus, the parallel computing technology will be extremely expansion of the use of R.  From R 2.14 (Feb 2012), ‘<a target="_blank" rel="noopener" href="https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf">parallel</a>‘ package is installed by default. Obviously, R core development team also attached great importance to parallelization. <a href="/oneXPU/uploads/2016/09/RPP.png"><img src="/oneXPU/uploads/2016/09/RPP.png"></a></p>
<h1 id="How-to-Use-Parallel-Computing"><a href="#How-to-Use-Parallel-Computing" class="headerlink" title="How to Use Parallel Computing?"></a>How to Use Parallel Computing?</h1><p>From the user’s view, parallel computing in R can be divided into implicit and explicit computing mode.</p>
<h2 id="Implicit-Mode"><a href="#Implicit-Mode" class="headerlink" title="Implicit Mode"></a>Implicit Mode</h2><p>Implicit computing hides most of the details for the user. It is not necessary to know how to allocate hardware resources, distribute workloads and gather results. The computations will start automatically based on the current hardware resources. Obviously, this mode is the most favorable. We can achieve higher performance without changing the calculation mode and our codes. Common implicit parallel mode includes:</p>
<ul>
<li>  Using Parallel Libraries</li>
</ul>
<p>Parallel libraries, such as <a target="_blank" rel="noopener" href="https://software.intel.com/en-us/intel-mkl">Intel MKL</a>，<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cublas">NVIDIA cuBLAS</a>,  <a target="_blank" rel="noopener" href="http://www.openblas.net/">OpenBLAS</a> are usually provided by the hardware manufacturer with in-depth optimizations based on the corresponding hardwares, so its performance is hugely better than R libraries. It is recommended choosing a high-performance R library at compile time or loading by LD_PRELOAD at runtime. The details of compiling, loading and using BLAS libraries can be found in the one of our previous blog (in <a target="_blank" rel="noopener" href="http://www.parallelr.com/r-hpac-benchmark-analysis/">here</a>). In the first diagram, the matrix calculation experiments, parallel libraries on 1 or 2 CPUs is a hundred times faster than R original library. On the second, we can see the GPU math library shows remarkable speed for some common analysis algorithms as well. <a href="/oneXPU/uploads/2016/09/mm.png"><img src="/oneXPU/uploads/2016/09/mm.png" alt="GEMM"></a> <a href="/oneXPU/uploads/2016/09/ca.png"><img src="/oneXPU/uploads/2016/09/ca.png" alt="GPU for R"></a> Now, let’s run an interesting example in which we didn’t call GEMM function explicitly but still get lots of performance improvements from parallel BLAS library. In below example, we train <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/MNIST_database">MNIST</a> dataset by DBN,deep belief network, (SRBM,Stacked Restricted Boltzmann Machine ) with <a target="_blank" rel="noopener" href="https://cran.r-project.org/web/packages/deepnet/index.html">deepnet</a> package. This example refers the blog of “<a target="_blank" rel="noopener" href="http://basicstatistics.tistory.com/entry/training-MNIST-data-with-the-package-deepnet">training MNIST data with the package deepnet</a>“ where the author got the accuracy of 0.004% on training data and 2% on testing data. Because the original network of <code>c(500,500,250,125)</code> is too huge to run, I simplified the network architecture in our case and the code of <code>deepnet_mnist.R</code> in <a target="_blank" rel="noopener" href="https://github.com/PatricZhao/ParallelR/blob/master/PP_for_COS/deepnet_mnist.R">here</a>.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#install.packages(&quot;data.table&quot;)</span></span><br><span class="line"><span class="comment">#install.packages(&quot;deepnet&quot;)</span></span><br><span class="line"> </span><br><span class="line">library(data.table)</span><br><span class="line">library(deepnet)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># download MNIST dataset in below links</span></span><br><span class="line"><span class="comment"># https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/train.csv.gz</span></span><br><span class="line"><span class="comment"># https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/test.csv.gz</span></span><br><span class="line">mnist.train &lt;- as.matrix(fread(<span class="string">&quot;./train.csv&quot;</span>, header=<span class="built_in">F</span>))</span><br><span class="line">mnist.test  &lt;- as.matrix(fread(<span class="string">&quot;./test.csv&quot;</span>, header=<span class="built_in">F</span>))</span><br><span class="line"> </span><br><span class="line"><span class="comment"># V785 is the label</span></span><br><span class="line">x &lt;- mnist.train[, <span class="number">1</span>:<span class="number">784</span>]/<span class="number">255</span></span><br><span class="line">y &lt;- model.matrix(~as.factor(mnist.train[, <span class="number">785</span>])-<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line">system.time(</span><br><span class="line">    nn &lt;- dbn.dnn.train(x,y,</span><br><span class="line">                        hidden=<span class="built_in">c</span>(<span class="number">64</span>),</span><br><span class="line">                        <span class="comment">#hidden=c(500,500,250,125),</span></span><br><span class="line">                        output=<span class="string">&quot;softmax&quot;</span>,</span><br><span class="line">                        batchsize=<span class="number">128</span>, </span><br><span class="line">                        numepochs=<span class="number">100</span>, </span><br><span class="line">                        learningrate = <span class="number">0.1</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>Thus, we run this piece of code twice. We got <strong>3.7X **and  **2.5X</strong>speedup (<strong>runtime of <a href="/oneXPU/uploads/2016/09/deepnet_Rnative-1.png">2581</a> sec .vs. <a href="/oneXPU/uploads/2016/09/deepnet_MKL.png">693</a> sec and <a href="/oneXPU/uploads/2016/09/deepnet_OpenBLAS.png">1213</a> sec</strong> )  by Intel MKL and OpenBLAS library on Intel SandyBridge E-2670.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt; R CMD BATCH deepnet_mnist.R</span><br><span class="line">&gt; cat deepnet_mnist.Rout</span><br><span class="line">deep nn has been trained.</span><br><span class="line">     user system   elapsed </span><br><span class="line"> 2574.013  1.404  2581.882</span><br><span class="line"> </span><br><span class="line">&gt; env LD_PRELOAD=/.../tools/OpenBLAS/lib/libopenblas.so R CMD BATCH deepnet_mnist.R</span><br><span class="line">&gt; cat deepnet_mnist.Rout</span><br><span class="line">deep nn has been trained.</span><br><span class="line">     user    system  elapsed </span><br><span class="line"> 4752.005 25881.221 1213.644</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Compiled with Intel Compiler and MKL</span></span><br><span class="line">&gt; R CMD BATCH deepnet_mnist.R</span><br><span class="line">&gt; cat deepnet_mnist.Rout</span><br><span class="line">deep nn has been trained.</span><br><span class="line">      user  system elapsed </span><br><span class="line"> 10770.641 290.486 693.146</span><br></pre></td></tr></table></figure>
<ul>
<li>  Using MultiThreading Functions</li>
</ul>
<p><a target="_blank" rel="noopener" href="http://openmp.org/wp/">OpenMP</a> is a multithreading library based on shared memory architecture for application acceleration. The latest R has been opened OpenMP options (-fopenmp) at compile time on Linux, which means that some of the calculations can be run in multithreaded mode. For example , <code>dist</code> is implemented by multithreading with OpenMP. The example code as below (<a target="_blank" rel="noopener" href="https://github.com/PatricZhao/ParallelR/blob/master/PP_for_COS/ImplicitParallel_MT.R">ImplicitParallel_MT.R</a>):</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Comparison of single thread and multiple threads run</span></span><br><span class="line"><span class="comment"># using Internal function to set thread numbers, not very grace, but don&#x27;t find a good way till now.</span></span><br><span class="line"><span class="comment"># Ang suggestion?</span></span><br><span class="line">setNumThreads &lt;- <span class="keyword">function</span>(nums=<span class="number">1</span>) &#123;</span><br><span class="line">  .Internal(setMaxNumMathThreads(nums))</span><br><span class="line">  .Internal(setNumMathThreads(nums))</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment"># dataset from 2^6 to 2^11</span></span><br><span class="line"><span class="keyword">for</span>(i <span class="keyword">in</span> <span class="number">6</span>:<span class="number">11</span>) &#123;</span><br><span class="line">  ORDER &lt;- 2^i</span><br><span class="line">  m &lt;- matrix(rnorm(ORDER*ORDER),ORDER,ORDER)</span><br><span class="line">  setNumThreads(<span class="number">1</span>)</span><br><span class="line">  res &lt;- system.time(d &lt;- dist(m))</span><br><span class="line">  print(res)</span><br><span class="line">  setNumThreads(<span class="number">20</span>)</span><br><span class="line">  res &lt;- system.time(d &lt;- dist(m))</span><br><span class="line">  print(res)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><a href="/oneXPU/uploads/2016/09/dist.png"><img src="/oneXPU/uploads/2016/09/dist.png"></a></p>
<ul>
<li>  Using Parallel Packages</li>
</ul>
<p>In the list of <a target="_blank" rel="noopener" href="https://cran.r-project.org/web/views/HighPerformanceComputing.html">R high-performance computing</a>, there are lots of parallel packages and tools. These parallel packages can be used like any other R packages quickly and conveniently. R users can always focus on the problem itself, without having to think too much about parallelism implementations and performance issues. Take <a target="_blank" rel="noopener" href="http://www.h2o.ai/">H2O.ai</a> for example, it takes Java as the backend to achieve multi-threading and multi-nodes computing. Users only need to load the package, and then initialize H2O with thread number. After that subsequent calculations, such as GBM, GLM, DeepLearning algorithm, will automatically be assigned to multiple threads and multiple CPUs.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">library(h2o)</span><br><span class="line">h2o.init(nthreads = <span class="number">4</span>)</span><br><span class="line"><span class="comment"># Connection successful!</span></span><br><span class="line"><span class="comment"># R is connected to the H2O cluster: </span></span><br><span class="line"><span class="comment"># H2O cluster uptime: 1 hours 53 minutes </span></span><br><span class="line"><span class="comment"># H2O cluster version: 3.8.3.3 </span></span><br><span class="line"><span class="comment"># H2O cluster name: H2O_started_from_R_patricz_ywj416 </span></span><br><span class="line"><span class="comment"># H2O cluster total nodes: 1 </span></span><br><span class="line"><span class="comment"># H2O cluster total memory: 1.55 GB </span></span><br><span class="line"><span class="comment"># H2O cluster total cores: 4 </span></span><br><span class="line"><span class="comment"># H2O cluster allowed cores: 4 </span></span><br><span class="line"><span class="comment"># H2O cluster healthy: TRUE </span></span><br><span class="line"><span class="comment"># H2O Connection ip: localhost </span></span><br><span class="line"><span class="comment"># H2O Connection port: 54321 </span></span><br><span class="line"><span class="comment"># H2O Connection proxy: NA </span></span><br><span class="line"><span class="comment"># R Version: R version 3.3.0 (2016-05-03)</span></span><br></pre></td></tr></table></figure>
<h2 id="Explicit-Mode"><a href="#Explicit-Mode" class="headerlink" title="Explicit Mode"></a>Explicit Mode</h2><p>Explicit parallel computing requires the user to be able to deal with more details, including data partitions, task distributions, and final results collections. Users not only need to understand their own algorithms but also need to have a certain understanding of hardware and software stack. Thus, it’s a little difficult for users. Fortunately, parallel computing framework in R, such as <code>parallel</code>,<code>Rmpi</code> and <code>foreach</code>, provides the simple parallel programming approach by mapping structure. R users only need to transfer the code into the form of <code>*apply</code> or <code>for</code>, and then replace them by parallel APIs such as <code>mc*apply</code> or <code>foreach</code>. For more complex calculation flow, the user can repeat the process of map-and-reduce. <a href="/oneXPU/uploads/2016/09/mapping-1.png"><img src="/oneXPU/uploads/2016/09/mapping-1.png" alt="R Parallel Approaches"></a> Now, we show you a parallel example by solving quadratic equation with <code>*apply</code> and <code>for</code> style. The whole code in <a target="_blank" rel="noopener" href="https://github.com/PatricZhao/ParallelR/blob/master/PP_for_COS/ExplicitParallel.R">ExplicitParallel.R</a>. First, we present a non- vectorized function for solving the equation, which can handle several special cases, such as second quadratic coefficient is zero, or second and first quadratic term are zero, or the number of the square root is negative.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Not vectorized function</span></span><br><span class="line"><span class="comment"># Quadratic Equation: a*x^2 + b*x + c = 0</span></span><br><span class="line">solve.quad.eq &lt;- <span class="keyword">function</span>(a, b, <span class="built_in">c</span>) </span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment"># Not validate eqution: a and b are almost ZERO</span></span><br><span class="line">  <span class="keyword">if</span>(<span class="built_in">abs</span>(a) &lt; <span class="number">1e-8</span> &amp;&amp; <span class="built_in">abs</span>(b) &lt; <span class="number">1e-8</span>) <span class="built_in">return</span>(<span class="built_in">c</span>(<span class="literal">NA</span>, <span class="literal">NA</span>) )</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Not quad equation</span></span><br><span class="line">  <span class="keyword">if</span>(<span class="built_in">abs</span>(a) &lt; <span class="number">1e-8</span> &amp;&amp; <span class="built_in">abs</span>(b) &gt; <span class="number">1e-8</span>) <span class="built_in">return</span>(<span class="built_in">c</span>(-<span class="built_in">c</span>/b, <span class="literal">NA</span>))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># No Solution</span></span><br><span class="line">  <span class="keyword">if</span>(b*b - <span class="number">4</span>*a*<span class="built_in">c</span> &lt; <span class="number">0</span>) <span class="built_in">return</span>(<span class="built_in">c</span>(<span class="literal">NA</span>,<span class="literal">NA</span>))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Return solutions</span></span><br><span class="line">  x.delta &lt;- <span class="built_in">sqrt</span>(b*b - <span class="number">4</span>*a*<span class="built_in">c</span>)</span><br><span class="line">  x1 &lt;- (-b + x.delta)/(<span class="number">2</span>*a)</span><br><span class="line">  x2 &lt;- (-b - x.delta)/(<span class="number">2</span>*a)</span><br><span class="line"></span><br><span class="line">  <span class="built_in">return</span>(<span class="built_in">c</span>(x1, x2))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>And then, we randomly generated three big vectors to storage three coefficients.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Generate data </span></span><br><span class="line">len &lt;- 1e8</span><br><span class="line">a &lt;- runif(len, -<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">a[sample(len, <span class="number">100</span>,replace=<span class="literal">TRUE</span>)] &lt;- <span class="number">0</span></span><br><span class="line"> </span><br><span class="line">b &lt;- runif(len, -<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">c &lt;- runif(len, -<span class="number">10</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<h3 id="apply-IMPLEMENTATION"><a href="#apply-IMPLEMENTATION" class="headerlink" title="*apply IMPLEMENTATION:"></a>*<strong>apply IMPLEMENTATION:</strong></h3><p>First, we look at the serial code. The data is mapped into solver function,<code>solve.quad.eq </code>by <code>lapply</code>, and the results are saved into list finally.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># serial code</span></span><br><span class="line">system.time(</span><br><span class="line">  res1.s &lt;- lapply(<span class="number">1</span>:len, FUN = <span class="keyword">function</span>(x) &#123; solve.quad.eq(a[x], b[x], <span class="built_in">c</span>[x])&#125;)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>Next, we use the function of <code>mcLapply</code> (multicores) in <code>parallel</code> package to parallelize calculations in <code>lapply</code>. From the API interface, the usage of <code>mcLapply</code> is really similar with <code>lapply</code> in addition to specifying the core numbers. <code>mcLapply</code> creates multiple copies of the current R session based on Linux fork mechanism, and evenly assign compute tasks into multiple processes regarding with input index. Finally, the master R session will collect the results from all worker sessions. If we specify two worker processes, one process calculated <code>1:(len/2)</code> while another computing <code>(len/2+1):len</code>, and finally two parts of results will be merged into <code>res1.p</code>. However, due to the use of Linux mechanisms, this version can’t be executed on Windows platform.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># parallel, Linux and MAC platform</span></span><br><span class="line">library(parallel)</span><br><span class="line"><span class="comment"># multicores on Linux</span></span><br><span class="line">system.time(</span><br><span class="line">  res1.p &lt;- mclapply(<span class="number">1</span>:len, </span><br><span class="line">                      FUN = <span class="keyword">function</span>(x) &#123; solve.quad.eq(a[x], b[x], <span class="built_in">c</span>[x]) &#125;, </span><br><span class="line">                      mc.cores = <span class="number">4</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>For non-Linux users, we can use <code>parLapply</code> function in <code>parallel</code> package to achieve parallelism. <code>parLapply</code> function supports different platforms including Windows, Linux and Mac with better portability, but its usage is a little complicated than <code>mclapply</code>. Before using <code>parLapply</code> function, we need to create a computing group (cluster) first. Computing group is a software-level concept, which means how many R worker processes we need to create (Note: <code>par*apply</code> package will create several new R processes rather than copies of R master process from <code>mc*apply</code>). Theoretically, the size of the computing group is not affected by the hardware configuration.For example, we can create a group with 1000 R worker processes on any machine. In practice, we usually use the same size of computing group with hardware resources (such as physical cores) so that each worker process of R can be mapped to a physical core. In the following example, we start with <code>detectCores</code> function to determine the number of computing cores in the machine.It is noteworthy that <code>detectCores()</code> returns the number of <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Hyper-threading">Hyper-Threading</a> rather than real physical cores.For example, there are two physical cores on my laptop, and each core can simulate two hyperthreading , so <code>detectCores()</code> return value is 4. However, for many compute-intensive tasks, the Hyper-Threading is not much helpful for improving performance, so we use the parameter of <code>logical=FALSE</code> to get the actual number of physical cores and then create the same number group.Since the worker processes in the group is new R sessions, the data and functions of the parent process is not visible. Therefore, we have to broadcast the data and functions to all worker processes by <code>clusterExport</code> function. Finally <code>parLapply</code> will distribute the tasks to all R worker processes evenly, and then gather results back.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cluster on Windows</span></span><br><span class="line">cores &lt;- detectCores(logical = <span class="literal">FALSE</span>)</span><br><span class="line">cl &lt;- makeCluster(cores)</span><br><span class="line">clusterExport(cl, <span class="built_in">c</span>(<span class="string">&#x27;solve.quad.eq&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>))</span><br><span class="line">system.time(</span><br><span class="line">  res1.p &lt;- parLapply(cl, <span class="number">1</span>:len, <span class="keyword">function</span>(x) &#123; solve.quad.eq(a[x], b[x], <span class="built_in">c</span>[x]) &#125;)</span><br><span class="line">)</span><br><span class="line">stopCluster(cl)</span><br></pre></td></tr></table></figure>
<h3 id="for-IMPLEMENTATION"><a href="#for-IMPLEMENTATION" class="headerlink" title="for IMPLEMENTATION:"></a><strong>for IMPLEMENTATION:</strong></h3><p>The computation approach of <code>for</code> is very similar with <code>*apply</code>. In the following serial implementation, we created a matrix for storage results and update the results one by one in the inner loop.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># for style: serial code</span></span><br><span class="line">res2.s &lt;- matrix(<span class="number">0</span>, nrow=len, ncol = <span class="number">2</span>)</span><br><span class="line">system.time(</span><br><span class="line">  <span class="keyword">for</span>(i <span class="keyword">in</span> <span class="number">1</span>:len) &#123;</span><br><span class="line">      res2.s[i,] &lt;- solve.quad.eq(a[i], b[i], <span class="built_in">c</span>[i])</span><br><span class="line">  &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>For the for loop parallelization, we can use <code>%dopar%</code> in <code>foreach</code> package to distribute the computations to multiple R workers. <code>foreach</code> package provides a method of data mapping, but does not include the establishment of computing group.Therefore, we need to create a computing group by <code>doParallel</code> or <code>doMC</code> package. Creating computing group is as same as before, except setting backend of computations by <code>registerDoParallel</code>. Now we consider the data decomposition. Actually, we want each R worker process to deal with continuous computing tasks. Suppose we have two R worker processes, the process 1 computes from <code>1:len/2</code>, another process for <code>(len/2+1):len</code>. Therefore, in the following example code, we evenly distribute the vectors to computing group and each process calculates the size of <code>chunk.size</code>. Another important skill is using local matrix to save partial results in each process. Last, combine local results together by <code>.combine=&#39;rbind&#39;</code> parameter.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># foreach, work on Linux/Windows/Mac</span></span><br><span class="line">library(foreach)</span><br><span class="line">library(doParallel)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Real physical cores in my computer</span></span><br><span class="line">cores &lt;- detectCores(logical = <span class="literal">FALSE</span>)</span><br><span class="line">cl &lt;- makeCluster(cores)</span><br><span class="line">registerDoParallel(cl, cores=cores)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># clusterSplit are very convience to split data but it takes lots of extra memory</span></span><br><span class="line"><span class="comment"># chunks &lt;- clusterSplit(cl, 1:len)</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># split data by ourselves</span></span><br><span class="line">chunk.size &lt;- len/cores</span><br><span class="line"> </span><br><span class="line">system.time(</span><br><span class="line">  res2.p &lt;- foreach(i=<span class="number">1</span>:cores, .combine=<span class="string">&#x27;rbind&#x27;</span>) %dopar%</span><br><span class="line">  &#123; </span><br><span class="line">    <span class="comment"># local data for results</span></span><br><span class="line">    res &lt;- matrix(<span class="number">0</span>, nrow=chunk.size, ncol=<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">for</span>(x <span class="keyword">in</span> ((i-<span class="number">1</span>)*chunk.size+<span class="number">1</span>):(i*chunk.size)) &#123;</span><br><span class="line">        res[x - (i-<span class="number">1</span>)*chunk.size,] &lt;- solve.quad.eq(a[x], b[x], <span class="built_in">c</span>[x])</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># return local results</span></span><br><span class="line">    res</span><br><span class="line">  &#125;</span><br><span class="line">)</span><br><span class="line"> </span><br><span class="line">stopImplicitCluster()</span><br><span class="line">stopCluster(cl)</span><br></pre></td></tr></table></figure>
<p>Finally, we tested the code on Linux platform with 4 threads and can gain more than **3X speedup ** for every parallel implementation! <a href="/oneXPU/uploads/2016/09/EP.png"><img src="/oneXPU/uploads/2016/09/EP.png" alt="R explicit parallel mode"></a></p>
<h1 id="Challenges-and-Prospects"><a href="#Challenges-and-Prospects" class="headerlink" title="Challenges and Prospects"></a>Challenges and Prospects</h1><p><strong>Challenges</strong> :In practice, the problem needed to be resolved by parallel computing is not such simple as our examples. To parallelize R and its eco-system are still very difficult because,</p>
<ul>
<li>  R is a decentralized and non-commercial software</li>
</ul>
<p>R is not developed by a compact organization or company while most of R’s packages are contributed by users. It means that it is difficult to adjust and unify software architecture and design with the same philosophy. On the other hand, commercial software, such as Matlab, with unified development, maintenance, and management, can be relatively easier to restructure and reconstruct. Therefore, after several times update, the parallelism of commercial software will be much higher.</p>
<ul>
<li>  The infrastructure design of R is still single-threaded</li>
</ul>
<p>R was originally designed for single-threaded so that many of the underlying data structures and functions are not thread-safe. Therefore, lots of codes need to be rewritten or adjust for high-level parallel algorithms. But it likely will destroy the original design patterns.</p>
<ul>
<li>  The packages are highly dependent</li>
</ul>
<p>Assume that we use package B in R, and B depends on some functions of package A. If package B is improved by multithreading first; after that package A is also enhanced by parallelization. So, it is likely to appear hybrid parallel when we use package B. It may lead lots of strange errors (BUGs) and performance decrease if there is no comprehensive design and testing during developments. <strong>Prospects:</strong> How will the future of parallelism in R ?</p>
<ul>
<li>  High-performance components from commercial and research organizations</li>
</ul>
<p>Essentially, software developments are inseparable from the human and financial investments. The packages, such as <a target="_blank" rel="noopener" href="http://www.h2o.ai/">H2O</a>, <a target="_blank" rel="noopener" href="https://github.com/dmlc/mxnet">MXNet</a>, <a target="_blank" rel="noopener" href="https://software.intel.com/en-us/blogs/daal">Intel DAAL</a>, improve the performance significantly from parallelism with long-term supports.</p>
<ul>
<li>  Cloud Platform</li>
</ul>
<p>With the rise of cloud computing ,Data Analyst as a Services (DAAS) and Machine Learning as a Service (MLAS) are more and more popular.The major cloud providers optimize their tools, including R, from hardware deployments, database, high-level algorithms and explore much more parallelism in application level. For example, Microsoft recently launched a series supports for R in their cloud (<a target="_blank" rel="noopener" href="http://www.zdnet.com/article/microsofts-r-strategy/">here</a>). Therefore, parallel in R will be more transparent. The user does the same things in R, but the real computing will be distributed to the cloud.</p>
<hr>
<h2 id="Other-Articles-and-Slides-about-R-and-Parallel-Computing"><a href="#Other-Articles-and-Slides-about-R-and-Parallel-Computing" class="headerlink" title="Other Articles and Slides about R and Parallel Computing"></a><strong>Other Articles and Slides about R and Parallel Computing</strong></h2><ul>
<li>  Max Gordon, How-to go parallel in R – basics + tips, <a target="_blank" rel="noopener" href="http://gforge.se/2015/02/how-to-go-parallel-in-r-basics-tips/">here</a></li>
<li>  Marcus,A brief foray into parallel processing with R, <a target="_blank" rel="noopener" href="https://beckmw.wordpress.com/2014/01/21/a-brief-foray-into-parallel-processing-with-r/">here</a></li>
<li>  John Mount, A gentle introduction to parallel computing in R, <a target="_blank" rel="noopener" href="http://www.win-vector.com/blog/2016/01/parallel-computing-in-r/">here</a></li>
<li>  Guilherme Ludwig, Parallel computing with R, <a target="_blank" rel="noopener" href="http://www.stat.wisc.edu/~gvludwig/327-5/parallel.html#/">here</a></li>
<li>  Norman Matloff, GPU TUTORIAL, WITH R INTERFACING, <a target="_blank" rel="noopener" href="https://matloff.wordpress.com/2015/01/23/gpu-tutorial-with-r-interfacing/">here</a></li>
<li>  Grey, Running R in Parallel (the easy way), <a target="_blank" rel="noopener" href="http://blog.yhat.com/posts/running-r-in-parallel.html">here</a></li>
<li>  NIMBioS,Tutorial: Using R for HPC, <a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLRyq_4VPZ9g_g4b3An6VTkRX_c0tAHoAj">video</a></li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/oneXPU/tags/multicores/" rel="tag"># multicores</a>
              <a href="/oneXPU/tags/rstats/" rel="tag"># rstats</a>
              <a href="/oneXPU/tags/parallel-computing/" rel="tag"># parallel computing</a>
              <a href="/oneXPU/tags/R/" rel="tag"># R</a>
              <a href="/oneXPU/tags/cuBLAS/" rel="tag"># cuBLAS</a>
              <a href="/oneXPU/tags/MKL/" rel="tag"># MKL</a>
              <a href="/oneXPU/tags/BLAS/" rel="tag"># BLAS</a>
              <a href="/oneXPU/tags/doMC/" rel="tag"># doMC</a>
              <a href="/oneXPU/tags/doParallel/" rel="tag"># doParallel</a>
              <a href="/oneXPU/tags/foreach/" rel="tag"># foreach</a>
              <a href="/oneXPU/tags/mcapply/" rel="tag"># mcapply</a>
              <a href="/oneXPU/tags/parallel/" rel="tag"># parallel</a>
              <a href="/oneXPU/tags/parlapply/" rel="tag"># parlapply</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/oneXPU/2016/07/26/r-and-openmp-boosting-compiled-code-on-multi-core-cpu-s/" rel="prev" title="R and openMP: boosting compiled code on multi-core cpu-s">
      <i class="fa fa-chevron-left"></i> R and openMP: boosting compiled code on multi-core cpu-s
    </a></div>
      <div class="post-nav-item">
    <a href="/oneXPU/2017/01/24/parallel-computation-with-r-and-xgboost/" rel="next" title="Parallel Computation with R and XGBoost">
      Parallel Computation with R and XGBoost <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#What-is-Parallel-Computing%EF%BC%9F"><span class="nav-number">1.</span> <span class="nav-text">What is Parallel Computing？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Why-R-Needs-Parallel-Computing"><span class="nav-number">2.</span> <span class="nav-text">Why R Needs Parallel Computing?</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Solution%EF%BC%9FParallel-Computing"><span class="nav-number">2.1.</span> <span class="nav-text">Solution？Parallel Computing!</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#How-to-Use-Parallel-Computing"><span class="nav-number">3.</span> <span class="nav-text">How to Use Parallel Computing?</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Implicit-Mode"><span class="nav-number">3.1.</span> <span class="nav-text">Implicit Mode</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Explicit-Mode"><span class="nav-number">3.2.</span> <span class="nav-text">Explicit Mode</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#apply-IMPLEMENTATION"><span class="nav-number">3.2.1.</span> <span class="nav-text">*apply IMPLEMENTATION:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#for-IMPLEMENTATION"><span class="nav-number">3.2.2.</span> <span class="nav-text">for IMPLEMENTATION:</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Challenges-and-Prospects"><span class="nav-number">4.</span> <span class="nav-text">Challenges and Prospects</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Other-Articles-and-Slides-about-R-and-Parallel-Computing"><span class="nav-number">4.1.</span> <span class="nav-text">Other Articles and Slides about R and Parallel Computing</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Patric Zhao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-categories">
            <a href="/oneXPU/categories/">
          
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/oneXPU/tags/">
          
        <span class="site-state-item-count">56</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Patric Zhao</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/oneXPU/lib/anime.min.js"></script>
  <script src="/oneXPU/lib/velocity/velocity.min.js"></script>
  <script src="/oneXPU/lib/velocity/velocity.ui.min.js"></script>

<script src="/oneXPU/js/utils.js"></script>

<script src="/oneXPU/js/motion.js"></script>


<script src="/oneXPU/js/schemes/muse.js"></script>


<script src="/oneXPU/js/next-boot.js"></script>




  















  

  

</body>
</html>
