<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>R with Parallel Computing from User Perspectives | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="This article is originally published in Capital of Statistic by Chinese [link] and I would like to thank He Tong for lots of great suggestions. All code in this post can be found on GitHub [link].  D">
<meta property="og:type" content="article">
<meta property="og:title" content="R with Parallel Computing from User Perspectives">
<meta property="og:url" content="https://jitmatrix.github.io/oneXPU/2016/09/10/r-with-parallel-computing/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="This article is originally published in Capital of Statistic by Chinese [link] and I would like to thank He Tong for lots of great suggestions. All code in this post can be found on GitHub [link].  D">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://www.parallelr.com/wp-content/uploads/2016/09/sunway-taihulight.jpg">
<meta property="og:image" content="http://www.parallelr.com/wp-content/uploads/2016/09/cs.png">
<meta property="og:image" content="http://www.parallelr.com/wp-content/uploads/2016/09/RPP.png">
<meta property="og:image" content="http://www.parallelr.com/wp-content/uploads/2016/09/mm.png">
<meta property="og:image" content="http://www.parallelr.com/wp-content/uploads/2016/09/ca.png">
<meta property="og:image" content="http://www.parallelr.com/wp-content/uploads/2016/09/dist.png">
<meta property="og:image" content="http://www.parallelr.com/wp-content/uploads/2016/09/mapping-1.png">
<meta property="og:image" content="http://www.parallelr.com/wp-content/uploads/2016/09/EP.png">
<meta property="article:published_time" content="2016-09-10T09:10:31.000Z">
<meta property="article:modified_time" content="2020-12-19T06:26:33.163Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="multicores">
<meta property="article:tag" content="rstats">
<meta property="article:tag" content="parallel computing">
<meta property="article:tag" content="R">
<meta property="article:tag" content="cuBLAS">
<meta property="article:tag" content="MKL">
<meta property="article:tag" content="BLAS">
<meta property="article:tag" content="doMC">
<meta property="article:tag" content="doParallel">
<meta property="article:tag" content="foreach">
<meta property="article:tag" content="mcapply">
<meta property="article:tag" content="parallel">
<meta property="article:tag" content="parlapply">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://www.parallelr.com/wp-content/uploads/2016/09/sunway-taihulight.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://jitmatrix.github.io/oneXPU"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-r-with-parallel-computing" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2016/09/10/r-with-parallel-computing/" class="article-date">
  <time class="dt-published" datetime="2016-09-10T09:10:31.000Z" itemprop="datePublished">2016-09-10</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Accelerators/">Accelerators</a>►<a class="article-category-link" href="/categories/Accelerators/General/">General</a>►<a class="article-category-link" href="/categories/Accelerators/General/GPGPU/">GPGPU</a>►<a class="article-category-link" href="/categories/Accelerators/General/GPGPU/MultiCores/">MultiCores</a>►<a class="article-category-link" href="/categories/Accelerators/General/GPGPU/MultiCores/Performance-Optimizaiton/">Performance Optimizaiton</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      R with Parallel Computing from User Perspectives
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <hr>
<p><em>This article is originally published in <a target="_blank" rel="noopener" href="http://cos.name/">Capital of Statistic</a> by Chinese [<a target="_blank" rel="noopener" href="http://cos.name/2016/09/r-and-parallel-computing/">link</a>] and I would like to thank <a target="_blank" rel="noopener" href="http://www.sfu.ca/~hetongh/">He Tong</a> for lots of great suggestions.</em> <em>All code in this post can be found on GitHub [<a target="_blank" rel="noopener" href="https://github.com/PatricZhao/ParallelR/tree/master/PP_for_COS">link</a>].</em></p>
<hr>
<p>Data scientists are already very familiar with statistical software like <a target="_blank" rel="noopener" href="https://www.r-project.org/">R</a>, <a target="_blank" rel="noopener" href="http://www.sas.com/en_hk/home.html">SAS</a>, <a target="_blank" rel="noopener" href="http://www.ibm.com/analytics/us/en/technology/spss/">SPSS</a>, <a target="_blank" rel="noopener" href="http://www.mathworks.com/products/matlab">MATLAB</a>; however, some of them are relatively inexperienced in parallel computing. So, in this post, I will introduce you some basic concepts on the use of parallel computing in R.</p>
<h1 id="What-is-Parallel-Computing？"><a href="#What-is-Parallel-Computing？" class="headerlink" title="What is Parallel Computing？"></a>What is Parallel Computing？</h1><p><a target="_blank" rel="noopener" href="https://computing.llnl.gov/tutorials/parallel_comp/">Parallel computing</a>, specifically, should include <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Supercomputer">high-performance computers</a> and <a target="_blank" rel="noopener" href="http://whatis.techtarget.com/definition/parallel-processing-software">parallel software</a>. The peak performance of high-performance computers increases quickly. In the most recent ranking of the world’s TOP500 supercomputers, Chinese Sunway Taihu Light topped the list with 93 PFLOPS (<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Supercomputer">here</a>). For most individuals, small and medium enterprises, high-performance computers are too expensive. So, the application of high-performance computers is indeed limited, mainly in the field of national defense, military, aerospace and research areas. In recent years, with the rapid developments of multicore CPU, cheap cluster, and various accelerators (<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Nvidia_Tesla">NVIDIA GPU</a>, <a target="_blank" rel="noopener" href="http://www.intel.com/content/www/us/en/processors/xeon/xeon-phi-detail.html">Intel Xeon Phi</a>, <a target="_blank" rel="noopener" href="http://www.xilinx.com/training/fpga/fpga-field-programmable-gate-array.htm">FPGA</a>), personal computers has been comparable to high-performance computers. <a target="_blank" rel="noopener" href="http://www.parallelr.com/wp-content/uploads/2016/09/sunway-taihulight.jpg"><img src="http://www.parallelr.com/wp-content/uploads/2016/09/sunway-taihulight.jpg" alt="sunway-taihulight"></a> On the other hand, the software changes lag a lot. Imagine what software you’re using  supported parallel operations, Chrome, Visual Studio or R? <a target="_blank" rel="noopener" href="http://www.parallelr.com/wp-content/uploads/2016/09/cs.png"><img src="http://www.parallelr.com/wp-content/uploads/2016/09/cs.png" alt="common software"></a> Software parallelization requires more research and development supports. It is called <a target="_blank" rel="noopener" href="https://software.intel.com/en-us/articles/what-is-code-modernization">code modernization</a> for the procedure of changing the serial code to parallel, which sounds a very interesting work. But, in practice, a large number of bug fixes, data structure rewrite, uncertain software behaviors and cross-platform issues greatly increase the software development and maintenance costs.</p>
<h1 id="Why-R-Needs-Parallel-Computing"><a href="#Why-R-Needs-Parallel-Computing" class="headerlink" title="Why R Needs Parallel Computing?"></a>Why R Needs Parallel Computing?</h1><p>Let’s come back to R. As one of the most popular statistical software, R has a lot of advantages, such as a wealth of statistical models, data processing tools, and powerful visualization capabilities. However, with an increasing amount of data, R’s memory usage and computation mode limit R to scale. From the memory perspective, R uses in-memory calculation mode. All data need to be processed in the main memory (RAM). Obviously, its advantages are high computational efficiency and speed, but the drawback is that the size of the problem can be handled by R is very limited (&lt;RAM ). Secondly, R core is a single-threaded program. Thus, in the modern multi-core processors,  R can not effectively use all the computing cores. If the R went to the Sunway CPU of 260 computing cores, single-threaded R only take 1/260 computing power and waste other computing cores of 259/260.</p>
<h2 id="Solution？Parallel-Computing"><a href="#Solution？Parallel-Computing" class="headerlink" title="Solution？Parallel Computing!"></a><strong>Solution？Parallel Computing!</strong></h2><p>Parallel computing technology can solve the problem that single-core and memory capacity can not meet the application needs. Thus, the parallel computing technology will be extremely expansion of the use of R.  From R 2.14 (Feb 2012), ‘<a target="_blank" rel="noopener" href="https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf">parallel</a>‘ package is installed by default. Obviously, R core development team also attached great importance to parallelization. <a target="_blank" rel="noopener" href="http://www.parallelr.com/wp-content/uploads/2016/09/RPP.png"><img src="http://www.parallelr.com/wp-content/uploads/2016/09/RPP.png"></a></p>
<h1 id="How-to-Use-Parallel-Computing"><a href="#How-to-Use-Parallel-Computing" class="headerlink" title="How to Use Parallel Computing?"></a>How to Use Parallel Computing?</h1><p>From the user’s view, parallel computing in R can be divided into implicit and explicit computing mode.</p>
<h2 id="Implicit-Mode"><a href="#Implicit-Mode" class="headerlink" title="Implicit Mode"></a>Implicit Mode</h2><p>Implicit computing hides most of the details for the user. It is not necessary to know how to allocate hardware resources, distribute workloads and gather results. The computations will start automatically based on the current hardware resources. Obviously, this mode is the most favorable. We can achieve higher performance without changing the calculation mode and our codes. Common implicit parallel mode includes:</p>
<ul>
<li>  Using Parallel Libraries</li>
</ul>
<p>Parallel libraries, such as <a target="_blank" rel="noopener" href="https://software.intel.com/en-us/intel-mkl">Intel MKL</a>，<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cublas">NVIDIA cuBLAS</a>,  <a target="_blank" rel="noopener" href="http://www.openblas.net/">OpenBLAS</a> are usually provided by the hardware manufacturer with in-depth optimizations based on the corresponding hardwares, so its performance is hugely better than R libraries. It is recommended choosing a high-performance R library at compile time or loading by LD_PRELOAD at runtime. The details of compiling, loading and using BLAS libraries can be found in the one of our previous blog (in <a target="_blank" rel="noopener" href="http://www.parallelr.com/r-hpac-benchmark-analysis/">here</a>). In the first diagram, the matrix calculation experiments, parallel libraries on 1 or 2 CPUs is a hundred times faster than R original library. On the second, we can see the GPU math library shows remarkable speed for some common analysis algorithms as well. <a target="_blank" rel="noopener" href="http://www.parallelr.com/wp-content/uploads/2016/09/mm.png"><img src="http://www.parallelr.com/wp-content/uploads/2016/09/mm.png" alt="GEMM"></a> <a target="_blank" rel="noopener" href="http://www.parallelr.com/wp-content/uploads/2016/09/ca.png"><img src="http://www.parallelr.com/wp-content/uploads/2016/09/ca.png" alt="GPU for R"></a> Now, let’s run an interesting example in which we didn’t call GEMM function explicitly but still get lots of performance improvements from parallel BLAS library. In below example, we train <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/MNIST_database">MNIST</a> dataset by DBN,deep belief network, (SRBM,Stacked Restricted Boltzmann Machine ) with <a target="_blank" rel="noopener" href="https://cran.r-project.org/web/packages/deepnet/index.html">deepnet</a> package. This example refers the blog of “<a target="_blank" rel="noopener" href="http://basicstatistics.tistory.com/entry/training-MNIST-data-with-the-package-deepnet">training MNIST data with the package deepnet</a>“ where the author got the accuracy of 0.004% on training data and 2% on testing data. Because the original network of <code>c(500,500,250,125)</code> is too huge to run, I simplified the network architecture in our case and the code of <code>deepnet_mnist.R</code> in <a target="_blank" rel="noopener" href="https://github.com/PatricZhao/ParallelR/blob/master/PP_for_COS/deepnet_mnist.R">here</a>. [code language=”r”] #install.packages(“data.table”) #install.packages(“deepnet”) library(data.table) library(deepnet) # download MNIST dataset in below links # <a target="_blank" rel="noopener" href="https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/train.csv.gz">https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/train.csv.gz</a> # <a target="_blank" rel="noopener" href="https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/test.csv.gz">https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/test.csv.gz</a> mnist.train &lt;- as.matrix(fread(“./train.csv”, header=F)) mnist.test &lt;- as.matrix(fread(“./test.csv”, header=F)) # V785 is the label x &lt;- mnist.train[, 1:784]/255 y &lt;- model.matrix(~as.factor(mnist.train[, 785])-1) system.time( nn &lt;- dbn.dnn.train(x,y, hidden=c(64), #hidden=c(500,500,250,125), output=”softmax”, batchsize=128, numepochs=100, learningrate = 0.1) ) [/code] Thus, we run this piece of code twice. We got **3.7X **and  **2.5X**speedup (**runtime of <a target="_blank" rel="noopener" href="http://www.parallelr.com/wp-content/uploads/2016/09/deepnet_Rnative-1.png">2581</a> sec .vs. <a target="_blank" rel="noopener" href="http://www.parallelr.com/wp-content/uploads/2016/09/deepnet_MKL.png">693</a> sec and <a target="_blank" rel="noopener" href="http://www.parallelr.com/wp-content/uploads/2016/09/deepnet_OpenBLAS.png">1213</a> sec** )  by Intel MKL and OpenBLAS library on Intel SandyBridge E-2670. [code language=”r”] &gt; R CMD BATCH deepnet_mnist.R &gt; cat deepnet_mnist.Rout deep nn has been trained. user system elapsed 2574.013 1.404 2581.882 &gt; env LD_PRELOAD=/…/tools/OpenBLAS/lib/libopenblas.so R CMD BATCH deepnet_mnist.R &gt; cat deepnet_mnist.Rout deep nn has been trained. user system elapsed 4752.005 25881.221 1213.644 # Compiled with Intel Compiler and MKL &gt; R CMD BATCH deepnet_mnist.R &gt; cat deepnet_mnist.Rout deep nn has been trained. user system elapsed 10770.641 290.486 693.146 [/code]</p>
<ul>
<li>  Using MultiThreading Functions</li>
</ul>
<p><a target="_blank" rel="noopener" href="http://openmp.org/wp/">OpenMP</a> is a multithreading library based on shared memory architecture for application acceleration. The latest R has been opened OpenMP options (-fopenmp) at compile time on Linux, which means that some of the calculations can be run in multithreaded mode. For example , <code>dist</code> is implemented by multithreading with OpenMP. The example code as below (<a target="_blank" rel="noopener" href="https://github.com/PatricZhao/ParallelR/blob/master/PP_for_COS/ImplicitParallel_MT.R">ImplicitParallel_MT.R</a>): [code language=”r”] # Comparison of single thread and multiple threads run # using Internal function to set thread numbers, not very grace, but don’t find a good way till now. # Ang suggestion? setNumThreads &lt;- function(nums=1) { .Internal(setMaxNumMathThreads(nums)) .Internal(setNumMathThreads(nums)) } # dataset from 2^6 to 2^11 for(i in 6:11) { ORDER &lt;- 2^i m &lt;- matrix(rnorm(ORDER*ORDER),ORDER,ORDER) setNumThreads(1) res &lt;- system.time(d &lt;- dist(m)) print(res) setNumThreads(20) res &lt;- system.time(d &lt;- dist(m)) print(res) } [/code] <a target="_blank" rel="noopener" href="http://www.parallelr.com/wp-content/uploads/2016/09/dist.png"><img src="http://www.parallelr.com/wp-content/uploads/2016/09/dist.png"></a></p>
<ul>
<li>  Using Parallel Packages</li>
</ul>
<p>In the list of <a target="_blank" rel="noopener" href="https://cran.r-project.org/web/views/HighPerformanceComputing.html">R high-performance computing</a>, there are lots of parallel packages and tools. These parallel packages can be used like any other R packages quickly and conveniently. R users can always focus on the problem itself, without having to think too much about parallelism implementations and performance issues. Take <a target="_blank" rel="noopener" href="http://www.h2o.ai/">H2O.ai</a> for example, it takes Java as the backend to achieve multi-threading and multi-nodes computing. Users only need to load the package, and then initialize H2O with thread number. After that subsequent calculations, such as GBM, GLM, DeepLearning algorithm, will automatically be assigned to multiple threads and multiple CPUs.   [code language=”r”] library(h2o) h2o.init(nthreads = 4) # Connection successful! # R is connected to the H2O cluster: # H2O cluster uptime: 1 hours 53 minutes # H2O cluster version: 3.8.3.3 # H2O cluster name: H2O_started_from_R_patricz_ywj416 # H2O cluster total nodes: 1 # H2O cluster total memory: 1.55 GB # H2O cluster total cores: 4 # H2O cluster allowed cores: 4 # H2O cluster healthy: TRUE # H2O Connection ip: localhost # H2O Connection port: 54321 # H2O Connection proxy: NA # R Version: R version 3.3.0 (2016-05-03) [/code]  </p>
<h2 id="Explicit-Mode"><a href="#Explicit-Mode" class="headerlink" title="Explicit Mode"></a>Explicit Mode</h2><p>Explicit parallel computing requires the user to be able to deal with more details, including data partitions, task distributions, and final results collections. Users not only need to understand their own algorithms but also need to have a certain understanding of hardware and software stack. Thus, it’s a little difficult for users. Fortunately, parallel computing framework in R, such as <code>parallel</code>,<code>Rmpi</code> and <code>foreach</code>, provides the simple parallel programming approach by mapping structure. R users only need to transfer the code into the form of <code>*apply</code> or <code>for</code>, and then replace them by parallel APIs such as <code>mc*apply</code> or <code>foreach</code>. For more complex calculation flow, the user can repeat the process of map-and-reduce. <a target="_blank" rel="noopener" href="http://www.parallelr.com/wp-content/uploads/2016/09/mapping-1.png"><img src="http://www.parallelr.com/wp-content/uploads/2016/09/mapping-1.png" alt="R Parallel Approaches"></a> Now, we show you a parallel example by solving quadratic equation with <code>*apply</code> and <code>for</code> style. The whole code in <a target="_blank" rel="noopener" href="https://github.com/PatricZhao/ParallelR/blob/master/PP_for_COS/ExplicitParallel.R">ExplicitParallel.R</a>. First, we present a non- vectorized function for solving the equation, which can handle several special cases, such as second quadratic coefficient is zero, or second and first quadratic term are zero, or the number of the square root is negative. [code language=”r”] # Not vectorized function # Quadratic Equation: a*x^2 + b*x + c = 0 solve.quad.eq &lt;- function(a, b, c) { # Not validate eqution: a and b are almost ZERO if(abs(a) &lt; 1e-8 &amp;&amp; abs(b) &lt; 1e-8) return(c(NA, NA) ) # Not quad equation if(abs(a) &lt; 1e-8 &amp;&amp; abs(b) &gt; 1e-8) return(c(-c/b, NA)) # No Solution if(b*b - 4*a*c &lt; 0) return(c(NA,NA)) # Return solutions x.delta &lt;- sqrt(b*b - 4*a*c) x1 &lt;- (-b + x.delta)/(2*a) x2 &lt;- (-b - x.delta)/(2*a) return(c(x1, x2)) } [/code] And then, we randomly generated three big vectors to storage three coefficients. [code language=”r”] # Generate data len &lt;- 1e8 a &lt;- runif(len, -10, 10) a[sample(len, 100,replace=TRUE)] &lt;- 0 b &lt;- runif(len, -10, 10) c &lt;- runif(len, -10, 10) [/code]</p>
<h3 id="apply-IMPLEMENTATION"><a href="#apply-IMPLEMENTATION" class="headerlink" title="*apply IMPLEMENTATION:"></a>*<strong>apply IMPLEMENTATION:</strong></h3><p>First, we look at the serial code. The data is mapped into solver function,<code>solve.quad.eq </code>by <code>lapply</code>, and the results are saved into list finally. [code language=”r”] # serial code system.time( res1.s &lt;- lapply(1:len, FUN = function(x) { solve.quad.eq(a[x], b[x], c[x])}) ) [/code] Next, we use the function of <code>mcLapply</code> (multicores) in <code>parallel</code> package to parallelize calculations in <code>lapply</code>. From the API interface, the usage of <code>mcLapply</code> is really similar with <code>lapply</code> in addition to specifying the core numbers. <code>mcLapply</code> creates multiple copies of the current R session based on Linux fork mechanism, and evenly assign compute tasks into multiple processes regarding with input index. Finally, the master R session will collect the results from all worker sessions. If we specify two worker processes, one process calculated <code>1:(len/2)</code> while another computing <code>(len/2+1):len</code>, and finally two parts of results will be merged into <code>res1.p</code>. However, due to the use of Linux mechanisms, this version can’t be executed on Windows platform. [code language=”r”] # parallel, Linux and MAC platform library(parallel) # multicores on Linux system.time( res1.p &lt;- mclapply(1:len, FUN = function(x) { solve.quad.eq(a[x], b[x], c[x]) }, mc.cores = 4) ) [/code] For non-Linux users, we can use <code>parLapply</code> function in <code>parallel</code> package to achieve parallelism. <code>parLapply</code> function supports different platforms including Windows, Linux and Mac with better portability, but its usage is a little complicated than <code>mclapply</code>. Before using <code>parLapply</code> function, we need to create a computing group (cluster) first. Computing group is a software-level concept, which means how many R worker processes we need to create (Note: <code>par*apply</code> package will create several new R processes rather than copies of R master process from <code>mc*apply</code>). Theoretically, the size of the computing group is not affected by the hardware configuration.For example, we can create a group with 1000 R worker processes on any machine. In practice, we usually use the same size of computing group with hardware resources (such as physical cores) so that each worker process of R can be mapped to a physical core. In the following example, we start with <code>detectCores</code> function to determine the number of computing cores in the machine.It is noteworthy that <code>detectCores()</code> returns the number of <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Hyper-threading">Hyper-Threading</a> rather than real physical cores.For example, there are two physical cores on my laptop, and each core can simulate two hyperthreading , so <code>detectCores()</code> return value is 4. However, for many compute-intensive tasks, the Hyper-Threading is not much helpful for improving performance, so we use the parameter of <code>logical=FALSE</code> to get the actual number of physical cores and then create the same number group.Since the worker processes in the group is new R sessions, the data and functions of the parent process is not visible. Therefore, we have to broadcast the data and functions to all worker processes by <code>clusterExport</code> function. Finally <code>parLapply</code> will distribute the tasks to all R worker processes evenly, and then gather results back. [code language=”r”] # cluster on Windows cores &lt;- detectCores(logical = FALSE) cl &lt;- makeCluster(cores) clusterExport(cl, c(‘solve.quad.eq’, ‘a’, ‘b’, ‘c’)) system.time( res1.p &lt;- parLapply(cl, 1:len, function(x) { solve.quad.eq(a[x], b[x], c[x]) }) ) stopCluster(cl) [/code]</p>
<h3 id="for-IMPLEMENTATION"><a href="#for-IMPLEMENTATION" class="headerlink" title="for IMPLEMENTATION:"></a><strong>for IMPLEMENTATION:</strong></h3><p>The computation approach of <code>for</code> is very similar with <code>*apply</code>. In the following serial implementation, we created a matrix for storage results and update the results one by one in the inner loop. [code language=”r”] # for style: serial code res2.s &lt;- matrix(0, nrow=len, ncol = 2) system.time( for(i in 1:len) { res2.s[i,] &lt;- solve.quad.eq(a[i], b[i], c[i]) } ) [/code] For the for loop parallelization, we can use <code>%dopar%</code> in <code>foreach</code> package to distribute the computations to multiple R workers. <code>foreach</code> package provides a method of data mapping, but does not include the establishment of computing group.Therefore, we need to create a computing group by <code>doParallel</code> or <code>doMC</code> package. Creating computing group is as same as before, except setting backend of computations by <code>registerDoParallel</code>. Now we consider the data decomposition. Actually, we want each R worker process to deal with continuous computing tasks. Suppose we have two R worker processes, the process 1 computes from <code>1:len/2</code>, another process for <code>(len/2+1):len</code>. Therefore, in the following example code, we evenly distribute the vectors to computing group and each process calculates the size of <code>chunk.size</code>. Another important skill is using local matrix to save partial results in each process. Last, combine local results together by <code>.combine=&#39;rbind&#39;</code> parameter. [code language=”r”] # foreach, work on Linux/Windows/Mac library(foreach) library(doParallel) # Real physical cores in my computer cores &lt;- detectCores(logical = FALSE) cl &lt;- makeCluster(cores) registerDoParallel(cl, cores=cores) # clusterSplit are very convience to split data but it takes lots of extra memory # chunks &lt;- clusterSplit(cl, 1:len) # split data by ourselves chunk.size &lt;- len/cores system.time( res2.p &lt;- foreach(i=1:cores, .combine=’rbind’) %dopar% { # local data for results res &lt;- matrix(0, nrow=chunk.size, ncol=2) for(x in ((i-1)*chunk.size+1):(i*chunk.size)) { res[x - (i-1)*chunk.size,] &lt;- solve.quad.eq(a[x], b[x], c[x]) } # return local results res } ) stopImplicitCluster() stopCluster(cl) [/code] Finally, we tested the code on Linux platform with 4 threads and can gain more than **3X speedup ** for every parallel implementation! <a target="_blank" rel="noopener" href="http://www.parallelr.com/wp-content/uploads/2016/09/EP.png"><img src="http://www.parallelr.com/wp-content/uploads/2016/09/EP.png" alt="R explicit parallel mode"></a></p>
<h1 id="Challenges-and-Prospects"><a href="#Challenges-and-Prospects" class="headerlink" title="Challenges and Prospects"></a>Challenges and Prospects</h1><p><strong>Challenges</strong> :In practice, the problem needed to be resolved by parallel computing is not such simple as our examples. To parallelize R and its eco-system are still very difficult because,</p>
<ul>
<li>  R is a decentralized and non-commercial software</li>
</ul>
<p>R is not developed by a compact organization or company while most of R’s packages are contributed by users. It means that it is difficult to adjust and unify software architecture and design with the same philosophy. On the other hand, commercial software, such as Matlab, with unified development, maintenance, and management, can be relatively easier to restructure and reconstruct. Therefore, after several times update, the parallelism of commercial software will be much higher.</p>
<ul>
<li>  The infrastructure design of R is still single-threaded</li>
</ul>
<p>R was originally designed for single-threaded so that many of the underlying data structures and functions are not thread-safe. Therefore, lots of codes need to be rewritten or adjust for high-level parallel algorithms. But it likely will destroy the original design patterns.</p>
<ul>
<li>  The packages are highly dependent</li>
</ul>
<p>Assume that we use package B in R, and B depends on some functions of package A. If package B is improved by multithreading first; after that package A is also enhanced by parallelization. So, it is likely to appear hybrid parallel when we use package B. It may lead lots of strange errors (BUGs) and performance decrease if there is no comprehensive design and testing during developments. <strong>Prospects:</strong> How will the future of parallelism in R ?</p>
<ul>
<li>  High-performance components from commercial and research organizations</li>
</ul>
<p>Essentially, software developments are inseparable from the human and financial investments. The packages, such as <a target="_blank" rel="noopener" href="http://www.h2o.ai/">H2O</a>, <a target="_blank" rel="noopener" href="https://github.com/dmlc/mxnet">MXNet</a>, <a target="_blank" rel="noopener" href="https://software.intel.com/en-us/blogs/daal">Intel DAAL</a>, improve the performance significantly from parallelism with long-term supports.</p>
<ul>
<li>  Cloud Platform</li>
</ul>
<p>With the rise of cloud computing ,Data Analyst as a Services (DAAS) and Machine Learning as a Service (MLAS) are more and more popular.The major cloud providers optimize their tools, including R, from hardware deployments, database, high-level algorithms and explore much more parallelism in application level. For example, Microsoft recently launched a series supports for R in their cloud (<a target="_blank" rel="noopener" href="http://www.zdnet.com/article/microsofts-r-strategy/">here</a>). Therefore, parallel in R will be more transparent. The user does the same things in R, but the real computing will be distributed to the cloud.</p>
<hr>
<h2 id="Other-Articles-and-Slides-about-R-and-Parallel-Computing"><a href="#Other-Articles-and-Slides-about-R-and-Parallel-Computing" class="headerlink" title="Other Articles and Slides about R and Parallel Computing"></a><strong>Other Articles and Slides about R and Parallel Computing</strong></h2><ul>
<li>  Max Gordon, How-to go parallel in R – basics + tips, <a target="_blank" rel="noopener" href="http://gforge.se/2015/02/how-to-go-parallel-in-r-basics-tips/">here</a></li>
<li>  Marcus,A brief foray into parallel processing with R, <a target="_blank" rel="noopener" href="https://beckmw.wordpress.com/2014/01/21/a-brief-foray-into-parallel-processing-with-r/">here</a></li>
<li>  John Mount, A gentle introduction to parallel computing in R, <a target="_blank" rel="noopener" href="http://www.win-vector.com/blog/2016/01/parallel-computing-in-r/">here</a></li>
<li>  Guilherme Ludwig, Parallel computing with R, <a target="_blank" rel="noopener" href="http://www.stat.wisc.edu/~gvludwig/327-5/parallel.html#/">here</a></li>
<li>  Norman Matloff, GPU TUTORIAL, WITH R INTERFACING, <a target="_blank" rel="noopener" href="https://matloff.wordpress.com/2015/01/23/gpu-tutorial-with-r-interfacing/">here</a></li>
<li>  Grey, Running R in Parallel (the easy way), <a target="_blank" rel="noopener" href="http://blog.yhat.com/posts/running-r-in-parallel.html">here</a></li>
<li>  NIMBioS,Tutorial: Using R for HPC, <a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLRyq_4VPZ9g_g4b3An6VTkRX_c0tAHoAj">video</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://jitmatrix.github.io/oneXPU/2016/09/10/r-with-parallel-computing/" data-id="ckivbjgr2006c6lol3y4t3xrt" data-title="R with Parallel Computing from User Perspectives" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BLAS/" rel="tag">BLAS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MKL/" rel="tag">MKL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/R/" rel="tag">R</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cuBLAS/" rel="tag">cuBLAS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/doMC/" rel="tag">doMC</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/doParallel/" rel="tag">doParallel</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/foreach/" rel="tag">foreach</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/mcapply/" rel="tag">mcapply</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/multicores/" rel="tag">multicores</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/parallel/" rel="tag">parallel</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/parallel-computing/" rel="tag">parallel computing</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/parlapply/" rel="tag">parlapply</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/rstats/" rel="tag">rstats</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/01/24/parallel-computation-with-r-and-xgboost/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Parallel Computation with R and XGBoost
        
      </div>
    </a>
  
  
    <a href="/2016/08/15/r-cran-package-modernization-openmp/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">R and OpenMP:  CRAN Package Modernization</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/">Accelerators</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/GPGPU/">GPGPU</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/GPGPU/MultiCores/">MultiCores</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/GPGPU/Performance-Optimizaiton/">Performance Optimizaiton</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/General/">General</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/General/GPGPU/">GPGPU</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/General/GPGPU/MultiCores/">MultiCores</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/General/GPGPU/MultiCores/Performance-Optimizaiton/">Performance Optimizaiton</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/General/MPI/">MPI</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/General/MPI/MultiCores/">MultiCores</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/General/MPI/MultiCores/Performance-Optimizaiton/">Performance Optimizaiton</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/General/MPI/MultiCores/Performance-Optimizaiton/Vectorization/">Vectorization</a></li></ul></li></ul></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/MultiCores/">MultiCores</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/MultiCores/Performance-Optimizaiton/">Performance Optimizaiton</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Accelerators/MultiCores/Vectorization/">Vectorization</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/GPGPU/">GPGPU</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/GPGPU/Intel-Xeon-Phi/">Intel Xeon Phi</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GPGPU/MultiCores/">MultiCores</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/GPGPU/MultiCores/Performance-Optimizaiton/">Performance Optimizaiton</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/General/">General</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/General/MultiCores/">MultiCores</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Uncategorized/">Uncategorized</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/BLAS/" rel="tag">BLAS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CRAN/" rel="tag">CRAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GEMM/" rel="tag">GEMM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GPU/" rel="tag">GPU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/H2O/" rel="tag">H2O</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HPAC/" rel="tag">HPAC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HPC/" rel="tag">HPC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MIC/" rel="tag">MIC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MKL/" rel="tag">MKL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MNIST/" rel="tag">MNIST</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Maximum-Likelihood/" rel="tag">Maximum Likelihood</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/R/" rel="tag">R</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Rcpp/" rel="tag">Rcpp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SSE/" rel="tag">SSE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Xeon/" rel="tag">Xeon</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Xeon-Phi/" rel="tag">Xeon Phi</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/benchmark/" rel="tag">benchmark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/big-data/" rel="tag">big data</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/boost/" rel="tag">boost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/classification/" rel="tag">classification</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cuBLAS/" rel="tag">cuBLAS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/data-analytics/" rel="tag">data analytics</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/deep-learning/" rel="tag">deep learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dnn/" rel="tag">dnn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/doMC/" rel="tag">doMC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/doParallel/" rel="tag">doParallel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/foreach/" rel="tag">foreach</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gmatrix/" rel="tag">gmatrix</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gpuR/" rel="tag">gpuR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gputools/" rel="tag">gputools</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/high-performance/" rel="tag">high performance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/iris/" rel="tag">iris</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/knn/" rel="tag">knn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lightboost/" rel="tag">lightboost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learing/" rel="tag">machine learing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mcapply/" rel="tag">mcapply</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/memory-usage/" rel="tag">memory usage</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/multicores/" rel="tag">multicores</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/multit/" rel="tag">multit</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/multithreads/" rel="tag">multithreads</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mutlithreading/" rel="tag">mutlithreading</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mutltiGPU/" rel="tag">mutltiGPU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/neural-network/" rel="tag">neural network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nvblas/" rel="tag">nvblas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/openMP/" rel="tag">openMP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/openblas/" rel="tag">openblas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/parallel/" rel="tag">parallel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/parallel-computing/" rel="tag">parallel computing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/parlapply/" rel="tag">parlapply</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/performance-optimization/" rel="tag">performance optimization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/profiling/" rel="tag">profiling</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rstats/" rel="tag">rstats</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sklearn/" rel="tag">sklearn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/snow/" rel="tag">snow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/xgboost/" rel="tag">xgboost</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/BLAS/" style="font-size: 10px;">BLAS</a> <a href="/tags/CRAN/" style="font-size: 10px;">CRAN</a> <a href="/tags/CUDA/" style="font-size: 12px;">CUDA</a> <a href="/tags/GEMM/" style="font-size: 12px;">GEMM</a> <a href="/tags/GPU/" style="font-size: 14px;">GPU</a> <a href="/tags/H2O/" style="font-size: 12px;">H2O</a> <a href="/tags/HPAC/" style="font-size: 10px;">HPAC</a> <a href="/tags/HPC/" style="font-size: 12px;">HPC</a> <a href="/tags/MIC/" style="font-size: 10px;">MIC</a> <a href="/tags/MKL/" style="font-size: 14px;">MKL</a> <a href="/tags/MNIST/" style="font-size: 10px;">MNIST</a> <a href="/tags/Maximum-Likelihood/" style="font-size: 10px;">Maximum Likelihood</a> <a href="/tags/R/" style="font-size: 20px;">R</a> <a href="/tags/Rcpp/" style="font-size: 10px;">Rcpp</a> <a href="/tags/SSE/" style="font-size: 10px;">SSE</a> <a href="/tags/Xeon/" style="font-size: 10px;">Xeon</a> <a href="/tags/Xeon-Phi/" style="font-size: 10px;">Xeon Phi</a> <a href="/tags/benchmark/" style="font-size: 10px;">benchmark</a> <a href="/tags/big-data/" style="font-size: 10px;">big data</a> <a href="/tags/boost/" style="font-size: 10px;">boost</a> <a href="/tags/classification/" style="font-size: 10px;">classification</a> <a href="/tags/cuBLAS/" style="font-size: 16px;">cuBLAS</a> <a href="/tags/data-analytics/" style="font-size: 12px;">data analytics</a> <a href="/tags/deep-learning/" style="font-size: 14px;">deep learning</a> <a href="/tags/dnn/" style="font-size: 12px;">dnn</a> <a href="/tags/doMC/" style="font-size: 10px;">doMC</a> <a href="/tags/doParallel/" style="font-size: 10px;">doParallel</a> <a href="/tags/foreach/" style="font-size: 10px;">foreach</a> <a href="/tags/gmatrix/" style="font-size: 10px;">gmatrix</a> <a href="/tags/gpuR/" style="font-size: 10px;">gpuR</a> <a href="/tags/gputools/" style="font-size: 10px;">gputools</a> <a href="/tags/high-performance/" style="font-size: 10px;">high performance</a> <a href="/tags/iris/" style="font-size: 10px;">iris</a> <a href="/tags/knn/" style="font-size: 10px;">knn</a> <a href="/tags/lightboost/" style="font-size: 10px;">lightboost</a> <a href="/tags/machine-learing/" style="font-size: 10px;">machine learing</a> <a href="/tags/machine-learning/" style="font-size: 12px;">machine learning</a> <a href="/tags/mcapply/" style="font-size: 10px;">mcapply</a> <a href="/tags/memory-usage/" style="font-size: 10px;">memory usage</a> <a href="/tags/multicores/" style="font-size: 18px;">multicores</a> <a href="/tags/multit/" style="font-size: 10px;">multit</a> <a href="/tags/multithreads/" style="font-size: 10px;">multithreads</a> <a href="/tags/mutlithreading/" style="font-size: 10px;">mutlithreading</a> <a href="/tags/mutltiGPU/" style="font-size: 10px;">mutltiGPU</a> <a href="/tags/neural-network/" style="font-size: 10px;">neural network</a> <a href="/tags/nvblas/" style="font-size: 10px;">nvblas</a> <a href="/tags/openMP/" style="font-size: 12px;">openMP</a> <a href="/tags/openblas/" style="font-size: 12px;">openblas</a> <a href="/tags/parallel/" style="font-size: 10px;">parallel</a> <a href="/tags/parallel-computing/" style="font-size: 18px;">parallel computing</a> <a href="/tags/parlapply/" style="font-size: 10px;">parlapply</a> <a href="/tags/performance-optimization/" style="font-size: 16px;">performance optimization</a> <a href="/tags/profiling/" style="font-size: 12px;">profiling</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/rstats/" style="font-size: 20px;">rstats</a> <a href="/tags/sklearn/" style="font-size: 10px;">sklearn</a> <a href="/tags/snow/" style="font-size: 10px;">snow</a> <a href="/tags/xgboost/" style="font-size: 10px;">xgboost</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/04/07/r-hpac-benchmark-analysis-gpu/">R benchmark for High-Performance Analytics and Computing (II): GPU Packages</a>
          </li>
        
          <li>
            <a href="/2017/01/24/parallel-computation-with-r-and-xgboost/">Parallel Computation with R and XGBoost</a>
          </li>
        
          <li>
            <a href="/2016/09/10/r-with-parallel-computing/">R with Parallel Computing from User Perspectives</a>
          </li>
        
          <li>
            <a href="/2016/08/15/r-cran-package-modernization-openmp/">R and OpenMP:  CRAN Package Modernization</a>
          </li>
        
          <li>
            <a href="/2016/07/26/r-and-openmp-boosting-compiled-code-on-multi-core-cpu-s/">R and openMP: boosting compiled code on multi-core cpu-s</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2020 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>