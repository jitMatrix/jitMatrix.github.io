<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Parallel Computation with R and XGBoost | oneXPU</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="XGBoost is a comprehensive machine learning library for gradient boosting. It began from the Kaggle community for online machine learning challenges, and then maintained by the collaborative efforts f">
<meta property="og:type" content="article">
<meta property="og:title" content="Parallel Computation with R and XGBoost">
<meta property="og:url" content="https://jitmatrix.github.io/oneXPU/2017/01/24/parallel-computation-with-r-and-xgboost/index.html">
<meta property="og:site_name" content="oneXPU">
<meta property="og:description" content="XGBoost is a comprehensive machine learning library for gradient boosting. It began from the Kaggle community for online machine learning challenges, and then maintained by the collaborative efforts f">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://www.parallelr.com/wp-content/uploads/2016/11/xgboost-struct-1-1024x570.png">
<meta property="og:image" content="http://www.parallelr.com/wp-content/uploads/2017/01/xgboost-2.png">
<meta property="og:image" content="http://www.parallelr.com/wp-content/uploads/2016/11/SpeedFigure-1024x843.png">
<meta property="article:published_time" content="2017-01-24T05:05:13.000Z">
<meta property="article:modified_time" content="2020-12-19T06:37:18.634Z">
<meta property="article:author" content="Patric Zhao">
<meta property="article:tag" content="boost">
<meta property="article:tag" content="lightboost">
<meta property="article:tag" content="memory usage">
<meta property="article:tag" content="multicores">
<meta property="article:tag" content="python">
<meta property="article:tag" content="rstats">
<meta property="article:tag" content="sklearn">
<meta property="article:tag" content="xgboost">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://www.parallelr.com/wp-content/uploads/2016/11/xgboost-struct-1-1024x570.png">
  
    <link rel="alternate" href="/oneXPU/atom.xml" title="oneXPU" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/oneXPU/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/oneXPU/css/style.css">

  
    
<link rel="stylesheet" href="/oneXPU/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/oneXPU/" id="logo">oneXPU</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/oneXPU/" id="subtitle">Diving into Parallel Technology</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/oneXPU/">Home</a>
        
          <a class="main-nav-link" href="/oneXPU/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/oneXPU/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://jitmatrix.github.io/oneXPU"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-parallel-computation-with-r-and-xgboost" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/oneXPU/2017/01/24/parallel-computation-with-r-and-xgboost/" class="article-date">
  <time class="dt-published" datetime="2017-01-24T05:05:13.000Z" itemprop="datePublished">2017-01-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/oneXPU/categories/General/">General</a>►<a class="article-category-link" href="/oneXPU/categories/General/MultiCores/">MultiCores</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Parallel Computation with R and XGBoost
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p><a target="_blank" rel="noopener" href="https://github.com/dmlc/xgboost">XGBoost</a> is a comprehensive machine learning library for gradient boosting. It began from the Kaggle community for online machine learning challenges, and then maintained by the collaborative efforts from the developers in the community. It is well known for its accuracy, efficiency and flexibility for various interfaces: the computational module is implemented in C++, and currently provides interfaces for R, python, Julia and Java. Its corresponding R package, <a target="_blank" rel="noopener" href="https://github.com/dmlc/xgboost/tree/master/R-package">xgboost</a>, in this sense is non-typical in terms of the design and structure. Although it is common that an R package is a wrapper of another tool, not many packages have the backend supporting many ways of parallel computation. The structure of the Project can be illustrated as follows: <img src="http://www.parallelr.com/wp-content/uploads/2016/11/xgboost-struct-1-1024x570.png"> Although it is common that an R package is a wrapper of another tool, not many packages have the backend supporting many ways of parallel computation. In xgboost, most works are done in the C++ part in the above Figure. Since all interfaces share the same computational backend, there is not really a difference in terms of the accuracy or efficiency of the results from different interfaces. Users only need to prepare the data and parameters in the preferred language, then call the corresponding interface and wait for the training and prediction. This design puts most heavy works to the background, and only asks for the minimum support from each interface. For this reason, we can expect in the future there will be more languages wrapping the XGBoost backend and their users can enjoy the parallel training power. XGBoost implements a gradient boosting trees algorithm. A gradient boosting trees model trains a lot of decision trees or regression trees in a sequence, where only one tree is added to the model at a time, and every new tree depends on the previous trees. This nature limits the level of parallel computation, since we cannot build multiple trees simultaneously. Therefore, the parallel computation is introduced in a lower level, i.e. in the tree-building process at each step. <img src="http://www.parallelr.com/wp-content/uploads/2017/01/xgboost-2.png"> Specifically, the parallel computation takes place in the operation where the model scans through all features on each internal node and set a threshold. Say we have a 4-core CPU for the training computation, then XGBoost separate the features into 4 groups. For the splitting operation on a node, XGBoost distributes the operation on each feature to their corresponding core. The training data is stored in a piece of shared memory, each core only needs to access one group of features, and perform the computation individually. The implementation is done in C++ with the help of OpenMP. It is obvious that users can benefit fully from the parallel computation if the number of features is larger than the number of threads of the CPU. XGBoost also supports training on a cluster, or with external memory. We will briefly introduce them in the following parts.</p>
<hr>
<p>In the following part, we will demonstrate the performance of the R package with different parallel strategies. We hope this introduction can be an example of a computational efficient R package.</p>
<h2 id="1-Multi-threading-on-a-single-machine"><a href="#1-Multi-threading-on-a-single-machine" class="headerlink" title="1. Multi-threading on a single machine"></a><strong>1. Multi-threading on a single machine</strong></h2><p>XGBoost offers the option to parallel the training process in an implicit style on a single machine, which could be a workstation or even your own laptop. This is one of the reasons that the Kaggle community loves it. In R, the switch of multi-threading computation is just a parameter nthread: [code language=”r”]&gt;require(xgboost) &gt; x = matrix(rnorm(100*10000), 10000, 100) &gt; y = x %*% rnorm(100) + rnorm(1000) &gt; &gt;system.time({ + bst = xgboost(data = x, label = y, nthread = 1, nround = 100, verbose = FALSE) + }) user system elapsed 10.98 0.05 11.06 &gt; &gt;system.time({ + bst = xgboost(data = x, label = y, nthread = 4, nround = 100, verbose = FALSE) + }) user system elapsed 20.80 0.67 3.37 [/code] In the results from the toy example, there is a noticeable difference between the one-thread and four-thread trainings. As a comparison, we made the following figure from a competition data(<a target="_blank" rel="noopener" href="https://www.kaggle.com/c/higgs-boson/data">https://www.kaggle.com/c/higgs-boson/data</a>) on Kaggle. The experiments were run on a laptop with an i7-4700m CPU. <img src="http://www.parallelr.com/wp-content/uploads/2016/11/SpeedFigure-1024x843.png" alt="speedfigure"> The marks R and python are the vanilla gradient boosting machine implementation. XGBoost is the fastest when using only one thread. By employing 4 threads the process can be almost 4x faster. To reproduce the above results, one can find related scripts at:<a target="_blank" rel="noopener" href="https://github.com/dmlc/xgboost/tree/master/demo/kaggle-higgs">https://github.com/dmlc/xgboost/tree/master/demo/kaggle-higgs</a>. Note that the plot was made in 2015, thus the results may vary due to changes in the packages.</p>
<h2 id="2-Parallel-on-a-Cluster"><a href="#2-Parallel-on-a-Cluster" class="headerlink" title="2. Parallel on a Cluster"></a><strong>2. Parallel on a Cluster</strong></h2><p>For some cases where the size of data is too large to fit into the memory, people may set up a cluster to parallel the training process. However, a uniformed API of multi-nodes parallel computation for different interface languages is still left to be developed. The current standard way to parallel the training is to use the C++ backend with a configuration file which manages the model parameters and then submit it to Yarn. For further information, please read the official documentation: <a target="_blank" rel="noopener" href="http://xgboost.readthedocs.io/en/latest/tutorials/aws_yarn.html">http://xgboost.readthedocs.io/en/latest/tutorials/aws_yarn.html</a>. It is also possible to distribute the computation in one’s own cluster, but there’s no documentation provided yet. One thing worth noticing is that when performing multi-node parallel computation, the data is split by the rows, thus on each node it is (almost) impossible to search for the exact best splitting point. As a result, XGBoost switches to an approximate algorithm mentioned in <a target="_blank" rel="noopener" href="http://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf">this paper</a>. Briefly speaking, the approximate algorithm creates a histogram to represent each feature based on its numerial distribution. It reduces the amount of calculation on slaves, makes the reduce step easier, and maintains the precision at the same time.</p>
<h2 id="3-External-Memory"><a href="#3-External-Memory" class="headerlink" title="3. External Memory"></a><strong>3. External Memory</strong></h2><p>External memory is a compromise of large size of input and insufficient computational resources. The basic idea is simple: store the input data on an SSD, which is cheaper than memory and faster than HDD, and repeatedly load a chunk of data into memory to train the model partially. Comparing to the parallel training on a cluster, this strategy also uses the approximate algorithm, but is more convenient to configure and call, and is also cheaper for most users. To enable the external memory for R, we need to make sure that the compiler on your machine supports it. Usually it is fine with the latest gcc/clang. For windows users with mingw, however, is not able to try it out. The data files also need to be in the libsvm format on the disk. Files used in this demo can be downloaded at <a target="_blank" rel="noopener" href="https://github.com/dmlc/xgboost/tree/master/demo/data">https://github.com/dmlc/xgboost/tree/master/demo/data</a>. Here’s the usual way to load the data into memory with xgboost’s own data structure: [code language=”r”]&gt;dtrain = xgb.DMatrix(‘agaricus.txt.train’) [15:57:38] 6513x127 matrix with 143286 entries loaded from agaricus.txt.train &gt;dtest = xgb.DMatrix(‘agaricus.txt.test’) [15:57:38] 1611x127 matrix with 35442 entries loaded from agaricus.txt.test &gt; &gt;model = xgboost(data = dtrain, nround = 2, objective = “binary:logistic”) [1] train-error:0.000614 [2] train-error:0.001228 [/code] Now if we add the suffix: [code language=”r”]&gt;dtrain = xgb.DMatrix(‘agaricus.txt.train#train.cache’) [15:57:45] SparsePage::Writer Finished writing to train.r0-1.cache.row.page [15:57:45] SparsePageSource: Finished writing to train.r0-1.cache [15:57:45] 6513x127 matrix with 143286 entries loaded from agaricus.txt.train#train.cache &gt;dtest = xgb.DMatrix(‘agaricus.txt.test#test.cache’) [15:57:45] SparsePage::Writer Finished writing to test.r0-1.cache.row.page [15:57:45] SparsePageSource: Finished writing to test.r0-1.cache [15:57:45] 1611x127 matrix with 35442 entries loaded from agaricus.txt.test#test.cache &gt; &gt;model = xgboost(data = dtrain, nround = 2, objective = “binary:logistic”) [15:57:45] SparsePage::Writer Finished writing to train.r0-1.cache.col.page [1] train-error:0.000614 [2] train-error:0.001228 [/code] Note the only difference is just the suffix: A “#” and the string following. The suffix can be arbitrary string as the prefix of the generated cache files, as printed in the output. With the suffix, the function automatically marks the file for external memory training. In the external memory mode we can also perform multi-threading training for each chunk of data, because the chunks are taken into the training process in a linear relationship. More details are included in <a target="_blank" rel="noopener" href="http://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf">this paper</a>.</p>
<hr>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>XGBoost puts effort in the three popular parallel computation solutions, multithreading, distributed parallel and <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Out-of-core_algorithm">out-of-cores</a> computations. The idea of this project is to only expose necessary APIs for different language interface design, and hide most computational details in the backend. So far the library is fast and user-friendly, we wish it could inspire more R package developers to balance the design and efficiency. The development will be continued, and contributions on code and ideas are always welcome :)</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://jitmatrix.github.io/oneXPU/2017/01/24/parallel-computation-with-r-and-xgboost/" data-id="ckivbxbgn000azroe4r9i4n6v" data-title="Parallel Computation with R and XGBoost" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/oneXPU/tags/boost/" rel="tag">boost</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/oneXPU/tags/lightboost/" rel="tag">lightboost</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/oneXPU/tags/memory-usage/" rel="tag">memory usage</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/oneXPU/tags/multicores/" rel="tag">multicores</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/oneXPU/tags/python/" rel="tag">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/oneXPU/tags/rstats/" rel="tag">rstats</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/oneXPU/tags/sklearn/" rel="tag">sklearn</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/oneXPU/tags/xgboost/" rel="tag">xgboost</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/oneXPU/2017/04/07/r-hpac-benchmark-analysis-gpu/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          R benchmark for High-Performance Analytics and Computing (II): GPU Packages
        
      </div>
    </a>
  
  
    <a href="/oneXPU/2016/09/10/r-with-parallel-computing/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">R with Parallel Computing from User Perspectives</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/Accelerators/">Accelerators</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/Accelerators/GPGPU/">GPGPU</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/Accelerators/GPGPU/MultiCores/">MultiCores</a></li><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/Accelerators/GPGPU/Performance-Optimizaiton/">Performance Optimizaiton</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/Accelerators/General/">General</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/Accelerators/General/GPGPU/">GPGPU</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/Accelerators/General/GPGPU/MultiCores/">MultiCores</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/Accelerators/General/GPGPU/MultiCores/Performance-Optimizaiton/">Performance Optimizaiton</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/Accelerators/General/MPI/">MPI</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/Accelerators/General/MPI/MultiCores/">MultiCores</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/Accelerators/General/MPI/MultiCores/Performance-Optimizaiton/">Performance Optimizaiton</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/Accelerators/General/MPI/MultiCores/Performance-Optimizaiton/Vectorization/">Vectorization</a></li></ul></li></ul></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/Accelerators/MultiCores/">MultiCores</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/Accelerators/MultiCores/Performance-Optimizaiton/">Performance Optimizaiton</a></li><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/Accelerators/MultiCores/Vectorization/">Vectorization</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/GPGPU/">GPGPU</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/GPGPU/Intel-Xeon-Phi/">Intel Xeon Phi</a></li><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/GPGPU/MultiCores/">MultiCores</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/GPGPU/MultiCores/Performance-Optimizaiton/">Performance Optimizaiton</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/General/">General</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/oneXPU/categories/General/MultiCores/">MultiCores</a></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/BLAS/" rel="tag">BLAS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/CRAN/" rel="tag">CRAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/CUDA/" rel="tag">CUDA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/GEMM/" rel="tag">GEMM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/GPU/" rel="tag">GPU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/H2O/" rel="tag">H2O</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/HPAC/" rel="tag">HPAC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/HPC/" rel="tag">HPC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/MIC/" rel="tag">MIC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/MKL/" rel="tag">MKL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/MNIST/" rel="tag">MNIST</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/Maximum-Likelihood/" rel="tag">Maximum Likelihood</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/R/" rel="tag">R</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/Rcpp/" rel="tag">Rcpp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/SSE/" rel="tag">SSE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/Xeon/" rel="tag">Xeon</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/Xeon-Phi/" rel="tag">Xeon Phi</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/benchmark/" rel="tag">benchmark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/big-data/" rel="tag">big data</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/boost/" rel="tag">boost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/classification/" rel="tag">classification</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/cuBLAS/" rel="tag">cuBLAS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/data-analytics/" rel="tag">data analytics</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/deep-learning/" rel="tag">deep learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/dnn/" rel="tag">dnn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/doMC/" rel="tag">doMC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/doParallel/" rel="tag">doParallel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/foreach/" rel="tag">foreach</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/gmatrix/" rel="tag">gmatrix</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/gpuR/" rel="tag">gpuR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/gputools/" rel="tag">gputools</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/high-performance/" rel="tag">high performance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/iris/" rel="tag">iris</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/knn/" rel="tag">knn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/lightboost/" rel="tag">lightboost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/machine-learing/" rel="tag">machine learing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/machine-learning/" rel="tag">machine learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/mcapply/" rel="tag">mcapply</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/memory-usage/" rel="tag">memory usage</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/multicores/" rel="tag">multicores</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/multit/" rel="tag">multit</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/multithreads/" rel="tag">multithreads</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/mutlithreading/" rel="tag">mutlithreading</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/mutltiGPU/" rel="tag">mutltiGPU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/neural-network/" rel="tag">neural network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/nvblas/" rel="tag">nvblas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/openMP/" rel="tag">openMP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/openblas/" rel="tag">openblas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/parallel/" rel="tag">parallel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/parallel-computing/" rel="tag">parallel computing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/parlapply/" rel="tag">parlapply</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/performance-optimization/" rel="tag">performance optimization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/profiling/" rel="tag">profiling</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/rstats/" rel="tag">rstats</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/sklearn/" rel="tag">sklearn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/snow/" rel="tag">snow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/oneXPU/tags/xgboost/" rel="tag">xgboost</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/oneXPU/tags/BLAS/" style="font-size: 10px;">BLAS</a> <a href="/oneXPU/tags/CRAN/" style="font-size: 10px;">CRAN</a> <a href="/oneXPU/tags/CUDA/" style="font-size: 12px;">CUDA</a> <a href="/oneXPU/tags/GEMM/" style="font-size: 12px;">GEMM</a> <a href="/oneXPU/tags/GPU/" style="font-size: 14px;">GPU</a> <a href="/oneXPU/tags/H2O/" style="font-size: 12px;">H2O</a> <a href="/oneXPU/tags/HPAC/" style="font-size: 10px;">HPAC</a> <a href="/oneXPU/tags/HPC/" style="font-size: 12px;">HPC</a> <a href="/oneXPU/tags/MIC/" style="font-size: 10px;">MIC</a> <a href="/oneXPU/tags/MKL/" style="font-size: 14px;">MKL</a> <a href="/oneXPU/tags/MNIST/" style="font-size: 10px;">MNIST</a> <a href="/oneXPU/tags/Maximum-Likelihood/" style="font-size: 10px;">Maximum Likelihood</a> <a href="/oneXPU/tags/R/" style="font-size: 20px;">R</a> <a href="/oneXPU/tags/Rcpp/" style="font-size: 10px;">Rcpp</a> <a href="/oneXPU/tags/SSE/" style="font-size: 10px;">SSE</a> <a href="/oneXPU/tags/Xeon/" style="font-size: 10px;">Xeon</a> <a href="/oneXPU/tags/Xeon-Phi/" style="font-size: 10px;">Xeon Phi</a> <a href="/oneXPU/tags/benchmark/" style="font-size: 10px;">benchmark</a> <a href="/oneXPU/tags/big-data/" style="font-size: 10px;">big data</a> <a href="/oneXPU/tags/boost/" style="font-size: 10px;">boost</a> <a href="/oneXPU/tags/classification/" style="font-size: 10px;">classification</a> <a href="/oneXPU/tags/cuBLAS/" style="font-size: 16px;">cuBLAS</a> <a href="/oneXPU/tags/data-analytics/" style="font-size: 12px;">data analytics</a> <a href="/oneXPU/tags/deep-learning/" style="font-size: 14px;">deep learning</a> <a href="/oneXPU/tags/dnn/" style="font-size: 12px;">dnn</a> <a href="/oneXPU/tags/doMC/" style="font-size: 10px;">doMC</a> <a href="/oneXPU/tags/doParallel/" style="font-size: 10px;">doParallel</a> <a href="/oneXPU/tags/foreach/" style="font-size: 10px;">foreach</a> <a href="/oneXPU/tags/gmatrix/" style="font-size: 10px;">gmatrix</a> <a href="/oneXPU/tags/gpuR/" style="font-size: 10px;">gpuR</a> <a href="/oneXPU/tags/gputools/" style="font-size: 10px;">gputools</a> <a href="/oneXPU/tags/high-performance/" style="font-size: 10px;">high performance</a> <a href="/oneXPU/tags/iris/" style="font-size: 10px;">iris</a> <a href="/oneXPU/tags/knn/" style="font-size: 10px;">knn</a> <a href="/oneXPU/tags/lightboost/" style="font-size: 10px;">lightboost</a> <a href="/oneXPU/tags/machine-learing/" style="font-size: 10px;">machine learing</a> <a href="/oneXPU/tags/machine-learning/" style="font-size: 12px;">machine learning</a> <a href="/oneXPU/tags/mcapply/" style="font-size: 10px;">mcapply</a> <a href="/oneXPU/tags/memory-usage/" style="font-size: 10px;">memory usage</a> <a href="/oneXPU/tags/multicores/" style="font-size: 18px;">multicores</a> <a href="/oneXPU/tags/multit/" style="font-size: 10px;">multit</a> <a href="/oneXPU/tags/multithreads/" style="font-size: 10px;">multithreads</a> <a href="/oneXPU/tags/mutlithreading/" style="font-size: 10px;">mutlithreading</a> <a href="/oneXPU/tags/mutltiGPU/" style="font-size: 10px;">mutltiGPU</a> <a href="/oneXPU/tags/neural-network/" style="font-size: 10px;">neural network</a> <a href="/oneXPU/tags/nvblas/" style="font-size: 10px;">nvblas</a> <a href="/oneXPU/tags/openMP/" style="font-size: 12px;">openMP</a> <a href="/oneXPU/tags/openblas/" style="font-size: 12px;">openblas</a> <a href="/oneXPU/tags/parallel/" style="font-size: 10px;">parallel</a> <a href="/oneXPU/tags/parallel-computing/" style="font-size: 18px;">parallel computing</a> <a href="/oneXPU/tags/parlapply/" style="font-size: 10px;">parlapply</a> <a href="/oneXPU/tags/performance-optimization/" style="font-size: 16px;">performance optimization</a> <a href="/oneXPU/tags/profiling/" style="font-size: 12px;">profiling</a> <a href="/oneXPU/tags/python/" style="font-size: 10px;">python</a> <a href="/oneXPU/tags/rstats/" style="font-size: 20px;">rstats</a> <a href="/oneXPU/tags/sklearn/" style="font-size: 10px;">sklearn</a> <a href="/oneXPU/tags/snow/" style="font-size: 10px;">snow</a> <a href="/oneXPU/tags/xgboost/" style="font-size: 10px;">xgboost</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/oneXPU/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/oneXPU/archives/2017/01/">January 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/oneXPU/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/oneXPU/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/oneXPU/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/oneXPU/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/oneXPU/archives/2016/04/">April 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/oneXPU/archives/2016/03/">March 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/oneXPU/archives/2016/02/">February 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/oneXPU/2017/04/07/r-hpac-benchmark-analysis-gpu/">R benchmark for High-Performance Analytics and Computing (II): GPU Packages</a>
          </li>
        
          <li>
            <a href="/oneXPU/2017/01/24/parallel-computation-with-r-and-xgboost/">Parallel Computation with R and XGBoost</a>
          </li>
        
          <li>
            <a href="/oneXPU/2016/09/10/r-with-parallel-computing/">R with Parallel Computing from User Perspectives</a>
          </li>
        
          <li>
            <a href="/oneXPU/2016/08/15/r-cran-package-modernization-openmp/">R and OpenMP:  CRAN Package Modernization</a>
          </li>
        
          <li>
            <a href="/oneXPU/2016/07/26/r-and-openmp-boosting-compiled-code-on-multi-core-cpu-s/">R and openMP: boosting compiled code on multi-core cpu-s</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2020 Patric Zhao<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/oneXPU/" class="mobile-nav-link">Home</a>
  
    <a href="/oneXPU/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/oneXPU/js/jquery-3.4.1.min.js"></script>



  
<script src="/oneXPU/fancybox/jquery.fancybox.min.js"></script>




<script src="/oneXPU/js/script.js"></script>





  </div>
</body>
</html>